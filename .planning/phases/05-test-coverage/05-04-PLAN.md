---
phase: 05-test-coverage
plan: 04
type: execute
wave: 2
depends_on: ["05-01"]
files_modified:
  - src/lib/engine/__tests__/ml.test.ts
autonomous: true

must_haves:
  truths:
    - "`featureVectorToMLInput()` produces a 15-element array from a FeatureVector"
    - "`featureVectorToMLInput()` handles null/undefined fields with sensible defaults (mid-range values)"
    - "`featureVectorToMLInput()` clamps all values to 0-1 range"
    - "`predictWithML()` returns null when model is not available"
    - "`predictWithML()` returns a number in 0-100 range when model is loaded"
    - "`stratifiedSplit()` preserves label proportions in both train and test sets"
  artifacts:
    - path: "src/lib/engine/__tests__/ml.test.ts"
      provides: "Unit tests for featureVectorToMLInput, predictWithML, stratifiedSplit"
      min_lines: 80
  key_links:
    - from: "src/lib/engine/__tests__/ml.test.ts"
      to: "src/lib/engine/ml.ts"
      via: "import featureVectorToMLInput, predictWithML, stratifiedSplit"
      pattern: "import.*from.*ml"
---

<objective>
Write unit tests for ml.ts covering the feature vector bridge (null handling, clamping), prediction output range, model unavailability, and stratified split.

Purpose: ML bridge must map FeatureVector fields correctly and handle nulls gracefully.
Output: ml.test.ts with tests for featureVectorToMLInput, predictWithML, and stratifiedSplit.
</objective>

<execution_context>
@/Users/davideloreti/.claude/get-shit-done/workflows/execute-plan.md
@/Users/davideloreti/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-test-coverage/05-RESEARCH.md
@.planning/phases/05-test-coverage/05-01-SUMMARY.md
@src/lib/engine/ml.ts
@src/lib/engine/types.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Unit tests for featureVectorToMLInput and stratifiedSplit</name>
  <files>src/lib/engine/__tests__/ml.test.ts</files>
  <action>
Create `src/lib/engine/__tests__/ml.test.ts`.

Mock external dependencies:
- `vi.mock("@/lib/logger", ...)` — createLogger returns stub (debug/info/warn/error as vi.fn(), child returns itself)
- `vi.mock("@sentry/nextjs", ...)` — captureException and addBreadcrumb as vi.fn()
- `vi.mock("@/lib/supabase/service", ...)` — createServiceClient returns mock with storage.from().download() and storage.from().upload()
- `vi.mock("fs", ...)` — readFileSync as vi.fn()

Import `featureVectorToMLInput`, `predictWithML`, `stratifiedSplit` from `../ml`, and `makeFeatureVector` from `./factories`.

**describe('featureVectorToMLInput'):**

1. **Produces 15-element array**: Call with `makeFeatureVector()`. Assert result has length 15.

2. **All values in 0-1 range**: Call with makeFeatureVector(). Assert every element is `>= 0` and `<= 1`.

3. **Maps shareability to shareRate**: Call with `makeFeatureVector({ shareability: 8 })`. Assert result[0] (shareRate) equals `0.8` (8/10 clamped).

4. **Maps commentProvocation to commentRate**: Call with `makeFeatureVector({ commentProvocation: 6 })`. Assert result[1] equals `0.6`.

5. **Handles null durationSeconds**: Call with `makeFeatureVector({ durationSeconds: null })`. Assert result[6] (durationSeconds slot) equals `30/180` (default 30s / 180 cap) which is ~0.167.

6. **Handles null audioTrendingMatch**: Call with `makeFeatureVector({ audioTrendingMatch: null })`. Assert result[8] (hasTrendingSound) equals 0.

7. **Clamps extreme values**: Call with `makeFeatureVector({ shareability: 15 })` (above 10). Assert result[0] <= 1.0. Call with negative value — assert >= 0.

8. **Default mid-range for missing DeepSeek signals**: Call with `featureVectorToMLInput({})` (empty partial). All DeepSeek-derived features should use default 5/10 = 0.5.

**describe('stratifiedSplit'):**

9. **Preserves label proportions**: Create features/labels with 50 label-1, 30 label-2, 20 label-3. Call `stratifiedSplit(features, labels, 0.2, seededRng)`. Assert test set has ~10 label-1, ~6 label-2, ~4 label-3 (within +/-1).

10. **Train + test = total**: Assert train.features.length + test.features.length === 100 and same for labels.

11. **Deterministic with same seed**: Call stratifiedSplit twice with same RNG. Assert identical split indices.

For the seeded RNG in tests, create a simple counter-based RNG: `let i = 0; const rng = () => { i = (i * 1664525 + 1013904223) % 2**32; return i / 2**32; }` or import seededRandom if it's exported from ml.ts (it's not — it's internal). Use a simple deterministic function instead.
  </action>
  <verify>Run `pnpm test src/lib/engine/__tests__/ml.test.ts` — all featureVectorToMLInput and stratifiedSplit tests pass.</verify>
  <done>featureVectorToMLInput tests cover: array length, value range, field mapping, null handling, clamping, defaults. stratifiedSplit tests cover: proportion preservation, completeness, determinism.</done>
</task>

<task type="auto">
  <name>Task 2: Unit tests for predictWithML</name>
  <files>src/lib/engine/__tests__/ml.test.ts</files>
  <action>
In the same ml.test.ts file, add a `describe('predictWithML')` block.

The challenge: `predictWithML` calls `loadModel()` which uses module-level `cachedWeights` and Supabase Storage. Mock the loading path.

**Strategy**: Mock `@/lib/supabase/service` so `createServiceClient().storage.from().download()` returns controlled data. Since `cachedWeights` is module-level, use `vi.resetModules()` + dynamic `import()` for isolation between tests.

OR simpler: since storage.from().download() is already mocked, configure it to return model weights JSON for the "loaded" tests and error for "unavailable" tests.

For the mock Supabase storage client, build it like:
```typescript
const mockDownload = vi.fn();
const mockUpload = vi.fn();
vi.mock("@/lib/supabase/service", () => ({
  createServiceClient: vi.fn(() => ({
    storage: {
      from: vi.fn(() => ({
        download: mockDownload,
        upload: mockUpload,
      })),
    },
  })),
}));
```

**Test cases:**

1. **Returns null when model not available**: Mock download to return `{ data: null, error: { message: "not found" } }`. Use `vi.resetModules()` + dynamic import to get fresh module. Assert `predictWithML([...features])` resolves to null.

2. **Returns 0-100 score when model loaded**: Mock download to return a Blob containing valid ModelWeights JSON (create minimal weights: 5x15 weight matrix with small values, 5-element biases array, featureNames array of 15 strings, numClasses: 5). Use `vi.resetModules()` + dynamic import. Assert result is a number between 0 and 100.

3. **Score is deterministic**: Call predictWithML twice with same features and same loaded model. Assert same result.

4. **Handles all-zero features**: Call with Array(15).fill(0). Assert returns a number (not NaN, not null).

Note: Use `beforeEach(() => { vi.resetModules(); })` to clear the module-level cachedWeights between tests. Then do `const { predictWithML } = await import('../ml')` inside each test.
  </action>
  <verify>Run `pnpm test src/lib/engine/__tests__/ml.test.ts` — all tests pass.</verify>
  <done>predictWithML tests cover: model unavailable returns null, loaded model returns 0-100, deterministic output, all-zero input edge case</done>
</task>

</tasks>

<verification>
1. `pnpm test src/lib/engine/__tests__/ml.test.ts` passes all tests
2. Tests cover featureVectorToMLInput (8 cases), stratifiedSplit (3 cases), predictWithML (4 cases)
3. Module-level state properly isolated between tests
</verification>

<success_criteria>
ML module tests verify: feature bridge produces correct 15-element arrays with clamping and null handling, prediction returns null or 0-100, stratified split preserves proportions.
</success_criteria>

<output>
After completion, create `.planning/phases/05-test-coverage/05-04-SUMMARY.md`
</output>
