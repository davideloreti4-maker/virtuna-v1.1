---
phase: 05-test-coverage
plan: 02
type: execute
wave: 2
depends_on: ["05-01"]
files_modified:
  - src/lib/engine/__tests__/aggregator.test.ts
autonomous: true

must_haves:
  truths:
    - "`selectWeights()` returns base weights {behavioral:0.35, gemini:0.25, ml:0.15, rules:0.15, trends:0.10} when all signals available"
    - "`selectWeights()` redistributes weight proportionally and sums to ~1.0 when any signal is missing"
    - "`selectWeights()` assigns 1.0 to the sole remaining source when only one signal is available"
    - "`aggregateScores()` clamps overall_score to 0-100 range"
    - "`aggregateScores()` returns confidence_label HIGH/MEDIUM/LOW based on confidence thresholds"
    - "`aggregateScores()` returns is_calibrated=false when Platt params unavailable"
    - "`aggregateScores()` builds correct feature_vector from PipelineResult"
  artifacts:
    - path: "src/lib/engine/__tests__/aggregator.test.ts"
      provides: "Unit tests for selectWeights, aggregateScores, confidence, feature vector assembly"
      min_lines: 100
  key_links:
    - from: "src/lib/engine/__tests__/aggregator.test.ts"
      to: "src/lib/engine/aggregator.ts"
      via: "import selectWeights, aggregateScores"
      pattern: "import.*from.*aggregator"
---

<objective>
Write unit tests for aggregator.ts covering weight selection, confidence calculation, feature vector assembly, and score clamping.

Purpose: The aggregator is the scoring core — weight redistribution must be correct for prediction accuracy.
Output: aggregator.test.ts with tests for selectWeights (6+ cases) and aggregateScores (4+ cases).
</objective>

<execution_context>
@/Users/davideloreti/.claude/get-shit-done/workflows/execute-plan.md
@/Users/davideloreti/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-test-coverage/05-RESEARCH.md
@.planning/phases/05-test-coverage/05-01-SUMMARY.md
@src/lib/engine/aggregator.ts
@src/lib/engine/types.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Unit tests for selectWeights</name>
  <files>src/lib/engine/__tests__/aggregator.test.ts</files>
  <action>
Create `src/lib/engine/__tests__/aggregator.test.ts`.

Mock external dependencies at the top of the file (these are imported transitively by aggregator.ts):
- `vi.mock("@/lib/logger", ...)` — return createLogger that returns stub log methods (debug/info/warn/error as vi.fn(), child returns itself)
- `vi.mock("@/lib/supabase/service", ...)` — return createServiceClient as vi.fn()
- `vi.mock("@sentry/nextjs", ...)` — captureException and addBreadcrumb as vi.fn()
- `vi.mock("@/lib/cache", ...)` — return createCache that returns { get: vi.fn(() => null), set: vi.fn(), invalidate: vi.fn() }

Then import `selectWeights` from `../aggregator`.

Write a `describe('selectWeights', ...)` block with these test cases:

1. **All signals available**: Input all true. Assert exact equality: `{ behavioral: 0.35, gemini: 0.25, ml: 0.15, rules: 0.15, trends: 0.10 }`.

2. **ML unavailable**: Input ml: false, rest true. Assert ml === 0, all others > their base weight, sum ~= 1.0 (use `toBeCloseTo(1, 2)`).

3. **Behavioral unavailable**: Input behavioral: false, rest true. Assert behavioral === 0, sum ~= 1.0.

4. **Multiple signals missing (behavioral + ml)**: Both false, rest true. Assert both === 0, remaining three redistribute, sum ~= 1.0.

5. **Single source available (only gemini)**: All false except gemini: true. Assert gemini ~= 1.0, all others === 0.

6. **All sources unavailable**: All false. Assert all weights are 0 (edge case — aggregator produces result object with all zeros, or NaN guard). Verify it doesn't throw.

7. **Weights always sum to ~1.0**: For each combo of 1-4 missing signals (test several), verify `Object.values(weights).reduce((a,b)=>a+b, 0)` is `toBeCloseTo(1, 2)`. The one exception is all-false which should sum to 0.

For floating point assertions, use `toBeCloseTo(expected, 2)` per research pitfall 4. The function rounds to 3 decimal places internally, so `toEqual` may work for base weights, but use `toBeCloseTo` for redistributed weights.
  </action>
  <verify>Run `pnpm test src/lib/engine/__tests__/aggregator.test.ts` — all tests pass.</verify>
  <done>selectWeights has 6+ test cases covering all-available, single-missing, multi-missing, single-source, and sum-to-1 invariant</done>
</task>

<task type="auto">
  <name>Task 2: Unit tests for aggregateScores (confidence, feature vector, score clamping, calibration)</name>
  <files>src/lib/engine/__tests__/aggregator.test.ts</files>
  <action>
In the same `aggregator.test.ts` file, add mocks for aggregator's direct imports:

- `vi.mock("../ml", ...)` — export `predictWithML` as vi.fn().mockResolvedValue(50) and `featureVectorToMLInput` as vi.fn().mockReturnValue(Array(15).fill(0.5))
- `vi.mock("../calibration", ...)` — export `getPlattParameters` as vi.fn().mockResolvedValue(null), `applyPlattScaling` as vi.fn((score, params) => score), and `PlattParameters` type
- `vi.mock("../gemini", ...)` — export `GEMINI_MODEL` as "gemini-test"
- `vi.mock("../deepseek", ...)` — export `DEEPSEEK_MODEL` as "deepseek-test"

Import `aggregateScores` from `../aggregator` and factory functions from `./factories`.

Write a `describe('aggregateScores', ...)` block with these test cases:

1. **Happy path — all signals**: Call `aggregateScores(makePipelineResult())`. Assert: overall_score is 0-100, confidence is 0-1, confidence_label is one of HIGH/MEDIUM/LOW, gemini_score is > 0, behavioral_score is > 0, ml_score is 50 (mocked), engine_version exists, score_weights has all 5 keys.

2. **Score clamping**: Mock predictWithML to return 200 (above max). Build a PipelineResult with gemini factors all scoring 10, deepseek component scores all 10. Assert overall_score <= 100. Then test with all zeros — assert overall_score >= 0.

3. **is_calibrated false when no Platt params**: getPlattParameters mock returns null. Call aggregateScores. Assert `is_calibrated === false`.

4. **is_calibrated true when Platt params available**: Mock `getPlattParameters` to resolve with `{ a: -1, b: 0, fittedAt: "2026-01-01", sampleCount: 100 }`. Mock `applyPlattScaling` to return 55 (modified score). Assert `is_calibrated === true`.

5. **Feature vector assembly**: Call aggregateScores. Assert `feature_vector` has all expected keys: hookScore, completionPull, rewatchPotential, shareTrigger, emotionalCharge, hookEffectiveness, retentionStrength, shareability, commentProvocation, saveWorthiness, trendAlignment, originality, ruleScore, trendScore, hashtagCount, hasVideo.

6. **DeepSeek null (behavioral unavailable)**: Build PipelineResult with `deepseekResult: null`. Assert behavioral_score === 0, score_weights.behavioral === 0, warnings includes "missing signals: behavioral".

7. **Confidence label thresholds**: Test that confidence >= 0.7 maps to "HIGH", >= 0.4 maps to "MEDIUM", < 0.4 maps to "LOW". May need to craft specific inputs to hit these thresholds (e.g., all signals available with high agreement = HIGH, few signals with disagreement = LOW).

Use `beforeEach` to reset all mocks with `vi.clearAllMocks()`.
  </action>
  <verify>Run `pnpm test src/lib/engine/__tests__/aggregator.test.ts` — all tests pass.</verify>
  <done>aggregateScores has 7+ test cases covering happy path, score clamping, calibration flag, feature vector shape, behavioral null, and confidence labels</done>
</task>

</tasks>

<verification>
1. `pnpm test src/lib/engine/__tests__/aggregator.test.ts` passes all tests
2. No TypeScript errors in test file
3. selectWeights tests cover: all-available, missing signals, single source, sum invariant
4. aggregateScores tests cover: happy path, clamping, calibration, feature vector, null deepseek, confidence
</verification>

<success_criteria>
Aggregator has comprehensive unit tests for weight selection (including redistribution edge cases) and score aggregation (including calibration, clamping, and feature vector assembly). All tests pass.
</success_criteria>

<output>
After completion, create `.planning/phases/05-test-coverage/05-02-SUMMARY.md`
</output>
