---
phase: 05-test-coverage
plan: 05
type: execute
wave: 2
depends_on: ["05-01"]
files_modified:
  - src/lib/engine/__tests__/calibration.test.ts
autonomous: true

must_haves:
  truths:
    - "`computeECE()` returns ECE=0 and empty bins for empty input"
    - "`computeECE()` bins pairs correctly and computes weighted gaps"
    - "`fitPlattScaling()` returns null for fewer than 50 samples"
    - "`fitPlattScaling()` returns PlattParameters with a, b, fittedAt, sampleCount for sufficient data"
    - "`applyPlattScaling()` returns rawScore unchanged when params is null"
    - "`applyPlattScaling()` applies sigmoid transformation and returns 0-100 range"
  artifacts:
    - path: "src/lib/engine/__tests__/calibration.test.ts"
      provides: "Unit tests for computeECE, fitPlattScaling, applyPlattScaling pure functions"
      min_lines: 80
  key_links:
    - from: "src/lib/engine/__tests__/calibration.test.ts"
      to: "src/lib/engine/calibration.ts"
      via: "import computeECE, fitPlattScaling, applyPlattScaling"
      pattern: "import.*from.*calibration"
---

<objective>
Write unit tests for calibration.ts pure functions: ECE computation, Platt scaling fitting, and Platt scaling application.

Purpose: Calibration math must be correct — ECE measures prediction quality, Platt scaling adjusts confidence.
Output: calibration.test.ts with tests for all three exported pure functions.
</objective>

<execution_context>
@/Users/davideloreti/.claude/get-shit-done/workflows/execute-plan.md
@/Users/davideloreti/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/lib/engine/calibration.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Unit tests for computeECE</name>
  <files>src/lib/engine/__tests__/calibration.test.ts</files>
  <action>
Create `src/lib/engine/__tests__/calibration.test.ts`.

Mock external dependencies (calibration.ts imports them at module level):
- `vi.mock("@/lib/logger", ...)` — createLogger returns stub
- `vi.mock("@sentry/nextjs", ...)` — captureException as vi.fn()
- `vi.mock("@/lib/supabase/service", ...)` — createServiceClient as vi.fn()
- `vi.mock("@/lib/cache", ...)` — createCache returns { get: vi.fn(() => null), set: vi.fn(), invalidate: vi.fn() }

Import `computeECE`, `fitPlattScaling`, `applyPlattScaling` from `../calibration`.

**describe('computeECE'):**

1. **Empty pairs returns ECE=0 and empty bins**: `computeECE([])` returns `{ ece: 0, bins: [] }`.

2. **Perfect calibration (ECE near 0)**: Create 100 pairs where predicted === actual (e.g., predicted: 0.5, actual: 0.5 for all). ECE should be 0 or very close to 0.

3. **Worst calibration (high ECE)**: Create pairs where predicted is always 0.9 but actual is always 0.1. ECE should be high (close to 0.8).

4. **Correct number of bins**: `computeECE(pairs, 10)` returns exactly 10 bins. `computeECE(pairs, 5)` returns exactly 5 bins.

5. **Bin boundaries**: Verify first bin has binStart=0, binEnd=0.1 (for 10 bins). Last bin has binStart=0.9, binEnd=1.0.

6. **All samples in single bin**: Create 10 pairs all with predicted=0.15 (falls in bin 1). Assert only bin 1 has count > 0, all others have count=0.

7. **Predicted=1.0 edge case**: A pair with predicted=1.0 should fall in the last bin (not overflow).

8. **ECE range**: Assert ECE is always >= 0 and <= 1.
  </action>
  <verify>Run `pnpm test src/lib/engine/__tests__/calibration.test.ts` — computeECE tests pass.</verify>
  <done>computeECE has 8 test cases covering: empty input, perfect calibration, worst calibration, bin count, boundaries, single-bin concentration, edge cases, range invariant</done>
</task>

<task type="auto">
  <name>Task 2: Unit tests for fitPlattScaling and applyPlattScaling</name>
  <files>src/lib/engine/__tests__/calibration.test.ts</files>
  <action>
In the same calibration.test.ts file, add two describe blocks.

**describe('fitPlattScaling'):**

1. **Returns null for fewer than 50 samples**: `fitPlattScaling(Array(49).fill({predicted: 0.5, actual: 0.5}))` returns null.

2. **Returns PlattParameters for >= 50 samples**: Create 100 pairs with realistic spread (predicted 0-1, actual slightly different). Assert result has `a` (number), `b` (number), `fittedAt` (string), `sampleCount` (100).

3. **Parameter a is negative for well-calibrated models**: Create 100 pairs where predicted roughly correlates with actual (e.g., actual = predicted * 0.9 + noise). Assert `result.a < 0` (the logistic model inversion).

4. **Exactly 50 samples works**: `fitPlattScaling(Array(50).fill({predicted: 0.5, actual: 0.5}))` returns non-null result.

5. **Deterministic**: Call twice with same input. Assert `a` and `b` are identical (no randomness in gradient descent).

**describe('applyPlattScaling'):**

6. **Null params returns rawScore unchanged**: `applyPlattScaling(75, null)` returns 75.

7. **Returns value in 0-100 range**: Apply with realistic params `{ a: -2, b: 1, fittedAt: "...", sampleCount: 100 }` for scores 0, 50, 100. Assert all results are >= 0 and <= 100.

8. **Sigmoid shape**: For a=-2, b=0: score 0 should map higher than score 100 (because sigmoid(A*x + B) with negative A is decreasing — wait, verify: calibrated = 1/(1+exp(A*normalized + B)). With A=-2, B=0, normalized=0 -> 1/(1+exp(0))=0.5, normalized=1 -> 1/(1+exp(-2))~0.88. So higher input -> higher output. Score 100 -> higher calibrated than score 0. Assert `applyPlattScaling(100, params) > applyPlattScaling(0, params)`.

9. **Identity-ish for a=-1, b=0**: Score 50 (normalized 0.5) -> 1/(1+exp(-0.5)) ~ 0.622 -> 62.2. Just verify it's a number in range — exact value depends on math.

10. **Rounded to 2 decimal places**: Result should have at most 2 decimal places (the function does `Math.round(clamped * 100) / 100`).
  </action>
  <verify>Run `pnpm test src/lib/engine/__tests__/calibration.test.ts` — all tests pass.</verify>
  <done>fitPlattScaling tests: min samples guard, parameter shape, negative A, determinism. applyPlattScaling tests: null passthrough, 0-100 range, monotonicity, rounding.</done>
</task>

</tasks>

<verification>
1. `pnpm test src/lib/engine/__tests__/calibration.test.ts` passes all tests
2. computeECE: 8 cases, fitPlattScaling: 5 cases, applyPlattScaling: 5 cases
3. All pure function tests — no Supabase calls, no network
</verification>

<success_criteria>
Calibration pure functions are fully tested: ECE computation handles all edge cases, Platt fitting respects minimum sample threshold and produces deterministic parameters, Platt application is monotonic and bounded.
</success_criteria>

<output>
After completion, create `.planning/phases/05-test-coverage/05-05-SUMMARY.md`
</output>
