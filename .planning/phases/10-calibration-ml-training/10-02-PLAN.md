---
phase: 10-calibration-ml-training
plan: 02
type: execute
wave: 2
depends_on: ["10-01"]
files_modified:
  - src/lib/engine/calibration.ts
autonomous: true

must_haves:
  truths:
    - "Platt scaling fits logistic regression coefficients (A, B) from outcome data"
    - "applyPlattScaling transforms a raw 0-100 score into a recalibrated 0-100 score"
    - "Platt parameters are cached in memory with TTL to avoid re-fitting on every request"
    - "When insufficient data exists (<50 outcomes), Platt scaling returns the raw score unchanged"
  artifacts:
    - path: "src/lib/engine/calibration.ts"
      provides: "Platt scaling fit and apply functions"
      exports: ["fitPlattScaling", "applyPlattScaling", "PlattParameters"]
  key_links:
    - from: "src/lib/engine/calibration.ts"
      to: "outcomes table"
      via: "fetchOutcomePairs reuse"
      pattern: "fetchOutcomePairs"
---

<objective>
Add Platt scaling to calibration.ts — a logistic regression-based recalibration that corrects systematic over/under-confidence in prediction scores.

Purpose: Raw engine scores may be systematically miscalibrated (e.g., consistently predicting 70 when actual outcomes average 55). Platt scaling fits a logistic curve to predicted vs actual data, producing A and B coefficients that recalibrate scores. This is the industry-standard approach used by weather forecasters and ML systems.

Output: `fitPlattScaling()` and `applyPlattScaling()` functions added to `src/lib/engine/calibration.ts`.
</objective>

<execution_context>
@/Users/davideloreti/.claude/get-shit-done/workflows/execute-plan.md
@/Users/davideloreti/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@src/lib/engine/calibration.ts
@src/lib/cache.ts
@.planning/phases/10-calibration-ml-training/10-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement Platt scaling fit and apply functions</name>
  <files>src/lib/engine/calibration.ts</files>
  <action>
Add the following to `src/lib/engine/calibration.ts` (extending the file from Plan 10-01):

**Types:**
- `PlattParameters`: `{ a: number; b: number; fittedAt: string; sampleCount: number }`

**Functions:**

1. `fitPlattScaling(pairs: OutcomePair[])` — pure function
   - Fits logistic regression: calibrated = 1 / (1 + exp(A * predicted + B))
   - Use gradient descent to minimize cross-entropy loss between calibrated predictions and actual outcomes
   - Implementation:
     - Initialize A = -1, B = 0 (reasonable defaults for score recalibration)
     - Learning rate = 0.01, iterations = 1000
     - For each iteration: compute gradients of cross-entropy loss w.r.t. A and B, update
     - Cross-entropy loss: -sum(actual * log(sigma) + (1-actual) * log(1-sigma)) where sigma = 1/(1+exp(A*pred+B))
     - Gradient for A: sum((sigma - actual) * predicted)
     - Gradient for B: sum(sigma - actual)
     - Clip sigma to [1e-7, 1-1e-7] to avoid log(0)
   - Return `PlattParameters` with fitted A, B, timestamp, and sample count
   - Minimum 50 samples required — return null if fewer (caller uses identity)

2. `applyPlattScaling(rawScore: number, params: PlattParameters | null)` — pure function
   - If params is null, return rawScore unchanged (identity — not enough data to calibrate)
   - Normalize rawScore from 0-100 to 0-1
   - Apply: calibrated = 1 / (1 + exp(params.a * normalized + params.b))
   - Scale back to 0-100, clamp to [0, 100], round to 2 decimal places
   - Return the recalibrated score

3. `getPlattParameters()` — async function with caching
   - Use `createCache<PlattParameters | null>(24 * 60 * 60 * 1000)` from `@/lib/cache` for 24hr TTL
   - Cache key: "platt-params"
   - On cache miss: fetch outcome pairs via `fetchOutcomePairs()`, call `fitPlattScaling()`, cache result
   - Return cached PlattParameters or null

Export: `fitPlattScaling`, `applyPlattScaling`, `getPlattParameters`, `PlattParameters`.

**Implementation notes:**
- Gradient descent is chosen over Newton's method for simplicity — with 1000 iterations and learning rate 0.01, convergence is reliable for this scale of data
- The 50-sample minimum prevents overfitting on tiny datasets — returns null so callers know to skip calibration
- 24hr cache TTL means parameters are re-fitted at most once per day (monthly cron in Plan 10-05 will force refresh)
- Pairs use 0-1 normalized scores (already handled by fetchOutcomePairs from Plan 10-01)
  </action>
  <verify>
Run `npx tsc --noEmit src/lib/engine/calibration.ts` to verify TypeScript compilation.
Verify: `fitPlattScaling([{predicted:0.8,actual:1},{predicted:0.3,actual:0},{predicted:0.6,actual:1},{predicted:0.2,actual:0},...])` produces non-null PlattParameters with reasonable A and B values (A should be negative, B near 0).
  </verify>
  <done>
Platt scaling functions exist in calibration.ts. fitPlattScaling produces A, B coefficients from outcome data. applyPlattScaling transforms raw scores using the fitted sigmoid. getPlattParameters caches fitted params for 24 hours. Identity fallback when <50 samples.
  </done>
</task>

</tasks>

<verification>
- `npx tsc --noEmit` passes for calibration.ts
- PlattParameters type is exported
- applyPlattScaling with null params returns input unchanged
- fitPlattScaling with <50 pairs returns null
</verification>

<success_criteria>
- Platt scaling recalibrates raw scores via logistic regression coefficients (A, B)
- Cached parameters avoid re-fitting on every request
- Graceful degradation with insufficient data
</success_criteria>

<output>
After completion, create `.planning/phases/10-calibration-ml-training/10-02-SUMMARY.md`
</output>
