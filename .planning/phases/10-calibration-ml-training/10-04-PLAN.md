---
phase: 10-calibration-ml-training
plan: 04
type: execute
wave: 2
depends_on: ["10-03"]
files_modified:
  - src/lib/engine/ml.ts
autonomous: true

must_haves:
  truths:
    - "ML model trains on extracted FeatureVectors and produces measurable accuracy on test set"
    - "Trained model weights are serializable to JSON for persistence"
    - "predictWithML accepts a partial feature array and returns a predicted virality score 0-100"
    - "Model achieves better-than-random accuracy on 5-tier classification (>20% = random baseline)"
  artifacts:
    - path: "src/lib/engine/ml.ts"
      provides: "ML model training, persistence, and inference"
      exports: ["trainModel", "predictWithML", "loadModel", "ModelWeights", "TrainingResult"]
  key_links:
    - from: "src/lib/engine/ml.ts"
      to: "src/lib/engine/training-data.json"
      via: "reads training data for model training"
      pattern: "training-data\\.json"
    - from: "src/lib/engine/ml.ts"
      to: "src/lib/engine/ml-weights.json"
      via: "persists and loads trained model weights"
      pattern: "ml-weights\\.json"
---

<objective>
Implement a lightweight ML model that trains on the extracted FeatureVector training data and produces virality score predictions. Uses a simple logistic regression / softmax classifier — no external ML libraries.

Purpose: The ML model provides a data-driven scoring signal that can complement the rule-based and LLM-based pipeline signals. Even a simple linear model trained on 7000+ real TikTok videos captures engagement patterns that heuristic rules miss.

Output: `src/lib/engine/ml.ts` with training, persistence, and inference functions.
</objective>

<execution_context>
@/Users/davideloreti/.claude/get-shit-done/workflows/execute-plan.md
@/Users/davideloreti/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@src/lib/engine/types.ts
@.planning/phases/10-calibration-ml-training/10-03-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement ML model training with multinomial logistic regression</name>
  <files>src/lib/engine/ml.ts</files>
  <action>
Create `src/lib/engine/ml.ts` with a from-scratch multinomial logistic regression (softmax classifier) — NO external ML libraries:

**Types:**
- `ModelWeights`: `{ weights: number[][]; biases: number[]; featureNames: string[]; numClasses: number; trainedAt: string; accuracy: number; confusionMatrix: number[][] }`
- `TrainingResult`: `{ weights: ModelWeights; trainAccuracy: number; testAccuracy: number; confusionMatrix: number[][] }`

**Core ML Functions:**

1. `softmax(logits: number[])` — internal helper
   - Compute exp(x_i - max) / sum(exp(x_j - max)) for numerical stability
   - Returns probability distribution over 5 classes

2. `trainModel(trainingDataPath?: string)` — async function
   - Default path: reads `src/lib/engine/training-data.json` (produced by Plan 10-03)
   - Read and parse the training data JSON
   - Train multinomial logistic regression with gradient descent:
     - 5 classes (virality tiers 1-5), 15 features
     - Weights matrix: 5 x 15, biases: 5
     - Initialize weights to small random values (seeded), biases to 0
     - Learning rate: 0.1, decay: 0.999 per epoch
     - Epochs: 200 (small dataset, converges fast)
     - L2 regularization: lambda = 0.001 to prevent overfitting
     - Loss: cross-entropy with softmax
     - Batch gradient descent (dataset small enough for full-batch)
   - After training:
     - Evaluate on test set: compute accuracy and confusion matrix
     - Log training accuracy, test accuracy
   - Persist weights to `src/lib/engine/ml-weights.json`
   - Return `TrainingResult`

3. `loadModel()` — sync function with caching
   - Read `src/lib/engine/ml-weights.json`
   - Cache in module-level variable (weights are static until retrained)
   - Return `ModelWeights` or null if file doesn't exist

4. `predictWithML(features: number[])` — sync function
   - Load model weights via `loadModel()`
   - If no model available, return null (graceful degradation)
   - Compute logits: weights * features + biases
   - Apply softmax to get class probabilities
   - Convert to score 0-100: weighted sum of (class_prob * tier_midpoint)
     - Tier 1 midpoint: 12.5, Tier 2: 35, Tier 3: 55, Tier 4: 72.5, Tier 5: 90
   - Return predicted score (0-100)

5. `featureVectorToMLInput(fv: Partial<FeatureVector>)` — helper
   - Convert a FeatureVector (from the prediction pipeline) to the 15-feature array format expected by the ML model
   - Map FeatureVector fields to training features:
     - Features not available from FeatureVector get sensible defaults (0.5 for unknown)
     - shareRate, commentRate, likeRate, saveRate are NOT in FeatureVector (they're engagement metrics) — use 0.5 defaults
     - Map: hookScore/10, completionPull/10, ruleScore/100, trendScore/100, hashtagCount/30 (capped), durationSeconds/180 (capped), hasVideo ? 1 : 0, audioTrendingMatch ?? 0, captionScore/10, hashtagRelevance, etc.
   - Note: The training data uses engagement metrics from scraped videos; the inference path uses pipeline features. This mapping bridges the two representations. The model's value comes from learning engagement patterns that transfer to content feature patterns.
   - Return `number[]` of length 15

**Important design decisions:**
- NO external ML libraries (TensorFlow, ONNX, etc.) — pure TypeScript implementation keeps the bundle small and deployment simple
- Multinomial logistic regression is interpretable and fast — right tradeoff for 15 features and 7000 samples
- L2 regularization prevents overfitting on the relatively small dataset
- Module-level weight caching means model loads once per server cold start
- Tier midpoints for score conversion preserve the ordinal nature of virality tiers
  </action>
  <verify>
Run `npx tsx -e "import { trainModel } from './src/lib/engine/ml'; trainModel().then(r => console.log('Train accuracy:', r.trainAccuracy, 'Test accuracy:', r.testAccuracy))"` — should complete and show accuracy > 20% (random baseline).
Verify ml-weights.json was created: `ls -la src/lib/engine/ml-weights.json`
Run `npx tsc --noEmit src/lib/engine/ml.ts` to verify compilation.
  </verify>
  <done>
ML model trains on 7000+ scraped video features, achieving measurably better-than-random accuracy on test set. Model weights persisted to ml-weights.json. predictWithML() returns a 0-100 virality score from feature input. featureVectorToMLInput() bridges pipeline FeatureVector to ML input format.
  </done>
</task>

</tasks>

<verification>
- `npx tsc --noEmit` passes for ml.ts
- Training completes without errors
- Test accuracy > 20% (random baseline for 5 classes)
- ml-weights.json exists and contains valid JSON
- predictWithML returns a number between 0-100
</verification>

<success_criteria>
- ML model trained on scraped video FeatureVectors with measurable accuracy on test set
- Model weights serialized to JSON for persistence
- Inference function available for pipeline integration
</success_criteria>

<output>
After completion, create `.planning/phases/10-calibration-ml-training/10-04-SUMMARY.md`
</output>
