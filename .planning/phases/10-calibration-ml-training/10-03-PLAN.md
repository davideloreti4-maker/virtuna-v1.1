---
phase: 10-calibration-ml-training
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - scripts/extract-training-data.ts
autonomous: true

must_haves:
  truths:
    - "Script extracts numeric features from scraped_videos that align with FeatureVector field structure"
    - "Each training sample has a feature array and a target label (virality tier 1-5 based on WES percentiles)"
    - "Output is a JSON file with train/test split (80/20) ready for ML consumption"
    - "Script handles missing data gracefully (null followers, null duration, missing metadata fields)"
  artifacts:
    - path: "scripts/extract-training-data.ts"
      provides: "Training data extraction from scraped_videos"
      exports: []
    - path: "src/lib/engine/training-data.json"
      provides: "Extracted training dataset with features and labels"
  key_links:
    - from: "scripts/extract-training-data.ts"
      to: "scraped_videos table"
      via: "direct Supabase query"
      pattern: "supabase\\.from\\(\"scraped_videos\"\\)"
    - from: "scripts/extract-training-data.ts"
      to: "src/lib/engine/calibration-baseline.json"
      via: "reads WES percentile thresholds for tier assignment"
      pattern: "calibration-baseline"
---

<objective>
Extract training data from 7000+ scraped TikTok videos into feature vectors with virality tier labels, producing a train/test split JSON file for ML model training.

Purpose: The ML model (Plan 10-04) needs structured numeric features derived from the same signals the FeatureVector uses. Since scraped videos don't have Gemini/DeepSeek analysis, we extract the features we CAN compute from raw video metadata: engagement rates, duration signals, hashtag counts, sound presence, creator size indicators.

Output: `scripts/extract-training-data.ts` script and `src/lib/engine/training-data.json` output file.
</objective>

<execution_context>
@/Users/davideloreti/.claude/get-shit-done/workflows/execute-plan.md
@/Users/davideloreti/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@scripts/analyze-dataset.ts
@src/lib/engine/types.ts
@src/lib/engine/calibration-baseline.json
@supabase/migrations/20260213000000_content_intelligence.sql
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create extract-training-data.ts script</name>
  <files>scripts/extract-training-data.ts</files>
  <action>
Create `scripts/extract-training-data.ts` following the same pattern as `scripts/analyze-dataset.ts` (dotenv + direct Supabase client, NOT the SSR variant):

**Setup (copy from analyze-dataset.ts):**
- `import { config } from "dotenv"` with path to `.env.local`
- `import { createClient } from "@supabase/supabase-js"`
- Load env vars, create Supabase client with service role key
- Same Database type import from `../src/types/database.types`

**Feature Extraction:**

Define `TrainingFeature` interface with 15 numeric features extractable from scraped video metadata:
1. `shareRate` — shares/views (most important signal, 3x weight in TikTok algo)
2. `commentRate` — comments/views (2x weight)
3. `likeRate` — likes/views (1x weight)
4. `saveRate` — bookmarks/views (from metadata.bookmarks)
5. `shareToLikeRatio` — shares/likes (distribution vs passive)
6. `commentToLikeRatio` — comments/likes (conversation depth)
7. `durationSeconds` — raw duration (normalized 0-1 by dividing by 180, capped at 1)
8. `hashtagCount` — number of hashtags (normalized 0-1 by dividing by 30, capped at 1)
9. `hasTrendingSound` — 1 if sound_name is non-empty, 0 otherwise
10. `captionLength` — description length (normalized 0-1 by dividing by 2000, capped at 1)
11. `hasFollowerData` — 1 if metadata.followers exists, 0 otherwise
12. `followerTier` — encoded: nano=0.1, micro=0.3, mid=0.5, macro=0.7, mega=0.9, unknown=0.5
13. `viewsPerFollower` — views/followers (capped at 50, normalized /50), 0 if no follower data
14. `weekdayPosted` — day of week from metadata.uploaded_at (0-6 normalized /6), 0.5 if unknown
15. `hourPosted` — hour from metadata.uploaded_at (0-23 normalized /23), 0.5 if unknown

**Label Assignment:**
- Read `src/lib/engine/calibration-baseline.json` to get WES percentile thresholds
- Compute WES for each video: (likes*1 + comments*2 + shares*3) / views
- Assign virality tier 1-5 based on calibration-baseline.json thresholds (same as analyze-dataset)
- Target label is the tier number (1-5), suitable for classification or ordinal regression

**Processing Pipeline:**
1. Fetch all non-archived scraped_videos in batches of 1000 (same pattern as analyze-dataset.ts)
2. Filter: views > 0, duration > 0 (same outlier rules)
3. For each video: compute features, assign label
4. Shuffle dataset deterministically (seed-based Fisher-Yates using simple hash of video ID)
5. Split 80/20 train/test
6. Write to `src/lib/engine/training-data.json`

**Output format:**
```json
{
  "generatedAt": "2026-02-16T...",
  "featureNames": ["shareRate", "commentRate", ...],
  "trainSet": { "features": [[0.02, 0.01, ...], ...], "labels": [3, 1, 5, ...], "count": 5856 },
  "testSet": { "features": [[...], ...], "labels": [...], "count": 1465 },
  "labelDistribution": { "1": 1830, "2": 1830, "3": 1830, "4": 1099, "5": 732 }
}
```

**Important:**
- Use the SAME utility functions from analyze-dataset.ts (copy percentile, mean, etc.) — don't import from it (it's a standalone script)
- Deterministic shuffle ensures reproducible train/test split
- All features normalized to roughly 0-1 range for ML compatibility
- DO NOT use any external ML libraries — this is just data extraction
  </action>
  <verify>
Run `npx tsx scripts/extract-training-data.ts` — should complete successfully and write training-data.json.
Verify output: `cat src/lib/engine/training-data.json | node -e "const d=JSON.parse(require('fs').readFileSync('/dev/stdin','utf8')); console.log('train:', d.trainSet.count, 'test:', d.testSet.count, 'features:', d.featureNames.length)"` — should show ~5800+ train, ~1400+ test, 15 features.
  </verify>
  <done>
extract-training-data.ts runs successfully, producing training-data.json with 15 features per sample, virality tier labels 1-5, and 80/20 train/test split from 7000+ scraped videos. All features normalized to 0-1 range.
  </done>
</task>

</tasks>

<verification>
- Script runs without errors against Supabase
- Output JSON has valid structure with train/test split
- Feature count matches 15
- All features are in 0-1 range (spot check a few samples)
- Label distribution roughly matches calibration-baseline virality tiers
</verification>

<success_criteria>
- Training data extracted from scraped videos with FeatureVector-aligned features
- 80/20 train/test split with deterministic shuffle
- Output ready for ML model consumption in Plan 10-04
</success_criteria>

<output>
After completion, create `.planning/phases/10-calibration-ml-training/10-03-SUMMARY.md`
</output>
