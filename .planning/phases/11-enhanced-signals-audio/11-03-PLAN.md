---
phase: 11-enhanced-signals-audio
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - src/app/api/cron/scrape-trending/route.ts
  - src/app/api/webhooks/apify/route.ts
autonomous: true

must_haves:
  truths:
    - "Scraper hashtag list is configurable via SCRAPER_HASHTAGS env var"
    - "Default hashtags include niche-specific tags beyond just fyp/viral/trending"
    - "Apify webhook stores the hashtag query that produced each batch for traceability"
  artifacts:
    - path: "src/app/api/cron/scrape-trending/route.ts"
      provides: "Configurable niche-specific hashtag scraping"
      contains: "SCRAPER_HASHTAGS"
    - path: "src/app/api/webhooks/apify/route.ts"
      provides: "Hashtag query traceability in scraped video metadata"
      contains: "scrape_hashtags"
  key_links:
    - from: "src/app/api/cron/scrape-trending/route.ts"
      to: "process.env.SCRAPER_HASHTAGS"
      via: "env var parsing for hashtag configuration"
      pattern: "SCRAPER_HASHTAGS"
    - from: "src/app/api/webhooks/apify/route.ts"
      to: "metadata.scrape_hashtags"
      via: "Apify run metadata forwarded to scraped_videos"
      pattern: "scrape_hashtags"
---

<objective>
Make the Apify scraper's hashtag list configurable via environment variable and expand the defaults to include niche-specific tags for better content coverage.

Purpose: Current scraper only fetches videos for 3 generic hashtags (`trending`, `viral`, `fyp`). This produces a biased dataset of generic content. Configurable niche-specific hashtags enable better trend detection per creator's niche.

Output: Updated `scrape-trending/route.ts` with env-based hashtag configuration, updated `webhooks/apify/route.ts` with hashtag traceability.
</objective>

<execution_context>
@/Users/davideloreti/.claude/get-shit-done/workflows/execute-plan.md
@/Users/davideloreti/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/app/api/cron/scrape-trending/route.ts
@src/app/api/webhooks/apify/route.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Configurable scraper hashtags via env var + expanded defaults</name>
  <files>src/app/api/cron/scrape-trending/route.ts</files>
  <action>
    Update `src/app/api/cron/scrape-trending/route.ts`:

    1. **Parse hashtags from env var:**
       ```typescript
       const DEFAULT_HASHTAGS = [
         "trending", "viral", "fyp",
         "comedy", "dance", "cooking", "fitness",
         "fashion", "beauty", "tech", "education",
         "storytelling", "lifehack", "motivation"
       ];

       function getScrapeHashtags(): string[] {
         const envHashtags = process.env.SCRAPER_HASHTAGS;
         if (!envHashtags) return DEFAULT_HASHTAGS;
         // Parse comma-separated, trim whitespace, filter empty
         const parsed = envHashtags.split(",").map(h => h.trim().toLowerCase()).filter(Boolean);
         return parsed.length > 0 ? parsed : DEFAULT_HASHTAGS;
       }
       ```

    2. **Use in actor start:**
       Replace the hardcoded `hashtags: ["trending", "viral", "fyp"]` in the Apify actor start call with `hashtags: getScrapeHashtags()`.

    3. **Pass hashtag list in webhook payload:**
       Add the hashtag list to the webhook payload template so the receiving webhook knows which query produced each batch:
       ```typescript
       payloadTemplate: `{
         "resource": {{resource}},
         "eventType": {{eventType}},
         "secret": "${process.env.APIFY_WEBHOOK_SECRET}",
         "scrape_hashtags": ${JSON.stringify(getScrapeHashtags())}
       }`,
       ```

    4. **Log which hashtags are being scraped:**
       Add a log line before starting the actor: `console.log(\`[scrape-trending] Scraping hashtags: \${hashtags.join(", ")}\`);`

    5. **Return hashtags in response:**
       Add `hashtags` to the success response JSON for monitoring.
  </action>
  <verify>
    ```bash
    npx tsc --noEmit src/app/api/cron/scrape-trending/route.ts
    ```
    Confirm no type errors.
  </verify>
  <done>
    - SCRAPER_HASHTAGS env var parsed when present, defaults used when absent
    - Default hashtags include 14 niche-spanning tags (not just 3 generic ones)
    - Hashtag list logged at scrape start for monitoring
    - Hashtag list passed in webhook payload for traceability
  </done>
</task>

<task type="auto">
  <name>Task 2: Store hashtag query in scraped video metadata for traceability</name>
  <files>src/app/api/webhooks/apify/route.ts</files>
  <action>
    Update `src/app/api/webhooks/apify/route.ts`:

    1. **Read scrape_hashtags from webhook payload:**
       Extract `payload.scrape_hashtags` (string array) from the incoming webhook. This was added to the payload template in Task 1.

    2. **Include in metadata:**
       In the record mapping (the `.map((item) => ({...}))` block), add `scrape_hashtags` to the `metadata` object:
       ```typescript
       metadata: {
         apify_dataset_id: resource.defaultDatasetId,
         apify_run_id: resource.id,
         scraped_at: new Date().toISOString(),
         scrape_hashtags: payload.scrape_hashtags ?? null,
       },
       ```

    3. **Log hashtag info:**
       In the success log, include which hashtags the batch was scraped for: `[apify-webhook] Processed ${items.length} items for hashtags: ${(payload.scrape_hashtags ?? []).join(", ")}`
  </action>
  <verify>
    ```bash
    npx tsc --noEmit src/app/api/webhooks/apify/route.ts
    ```
    Confirm no type errors.
  </verify>
  <done>
    - scrape_hashtags field stored in scraped_videos metadata JSONB column
    - Webhook handler logs which hashtags produced each batch
    - Graceful fallback when scrape_hashtags not present in payload (backward compat with old actor runs)
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes across all modified files
2. `pnpm build` completes without errors
3. SCRAPER_HASHTAGS env var is respected when set
4. Default hashtags include 14 niche-spanning tags
5. Webhook stores scrape_hashtags in metadata for traceability
</verification>

<success_criteria>
- Apify scraper supports configurable niche-specific hashtag lists via env var â€” SIG-04 satisfied
- Default hashtag list expanded from 3 generic to 14 niche-spanning tags
- Scrape metadata includes which hashtags produced each batch
</success_criteria>

<output>
After completion, create `.planning/phases/11-enhanced-signals-audio/11-03-SUMMARY.md`
</output>
