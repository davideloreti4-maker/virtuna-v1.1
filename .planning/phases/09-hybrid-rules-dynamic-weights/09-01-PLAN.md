---
phase: 09-hybrid-rules-dynamic-weights
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/engine/rules.ts
autonomous: true

must_haves:
  truths:
    - "Rules with evaluation_tier='regex' are scored via deterministic pattern matching"
    - "Rules with evaluation_tier='semantic' are scored via DeepSeek evaluation using their evaluation_prompt"
    - "Broken regex rules (loop_structure, emotional_arc, text_overlay) are classified as semantic tier"
    - "Semantic evaluation returns a 0-10 score per rule with a brief rationale"
    - "Rules that cannot be evaluated (no pattern for regex, no prompt for semantic) score 0 with a skip reason"
  artifacts:
    - path: "src/lib/engine/rules.ts"
      provides: "Hybrid regex+semantic rule evaluation with tiered scoring"
      exports: ["loadActiveRules", "scoreContentAgainstRules"]
  key_links:
    - from: "src/lib/engine/rules.ts"
      to: "src/lib/engine/deepseek.ts"
      via: "OpenAI client reuse pattern for semantic evaluation"
      pattern: "new OpenAI.*baseURL.*deepseek"
---

<objective>
Split rule evaluation into a deterministic regex tier and a semantic DeepSeek evaluation tier. Fix broken rules (loop_structure, emotional_arc, text_overlay) by routing them through semantic evaluation. Each rule's `evaluation_tier` column in DB determines which path it takes.

Purpose: RULE-01 (hybrid rules) and RULE-02 (fix broken rules). Currently, 3 rules always return false/true regardless of content. Semantic evaluation uses each rule's `evaluation_prompt` to get a nuanced 0-10 score from DeepSeek.

Output: Updated `src/lib/engine/rules.ts` with hybrid scoring.
</objective>

<execution_context>
@/Users/davideloreti/.claude/get-shit-done/workflows/execute-plan.md
@/Users/davideloreti/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/lib/engine/rules.ts
@src/lib/engine/deepseek.ts
@src/lib/engine/types.ts
@supabase/seed.sql
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement hybrid rule evaluation engine with regex and semantic tiers</name>
  <files>src/lib/engine/rules.ts</files>
  <action>
Rewrite `src/lib/engine/rules.ts` to support two evaluation tiers:

**1. Update the Rule interface** to include the new DB columns:
- Add `evaluation_tier: 'regex' | 'semantic'` (from Phase 4 migration)
- Ensure `evaluation_prompt` is already in the interface (it is)
- Update the `loadActiveRules` select query to include `evaluation_tier`

**2. Keep existing `matchesPattern()` function** as the regex tier handler. It already works for deterministic rules. No changes needed here.

**3. Create `evaluateSemanticRules()` function:**
- Takes content string and an array of semantic-tier rules
- Creates a single OpenAI client (same pattern as deepseek.ts: `new OpenAI({ apiKey: process.env.DEEPSEEK_API_KEY, baseURL: 'https://api.deepseek.com' })`) — reuse DeepSeek for semantic eval since it's cheaper than Gemini
- Batches ALL semantic rules into ONE DeepSeek call (not one call per rule — too expensive)
- Prompt structure:
  ```
  Evaluate the following content against these rules. For each rule, provide a score (0-10) and brief rationale (1 sentence).

  Content: {content}

  Rules to evaluate:
  1. {rule.name}: {rule.evaluation_prompt}
  2. {rule.name}: {rule.evaluation_prompt}
  ...

  Return JSON: { "evaluations": [{ "rule_name": string, "score": number, "rationale": string }] }
  ```
- Use `response_format: { type: 'json_object' }` for reliable JSON output
- Parse with a Zod schema: `z.object({ evaluations: z.array(z.object({ rule_name: z.string(), score: z.number().min(0).max(10), rationale: z.string() })) })`
- Timeout: 15s (semantic eval is simpler than full reasoning)
- On failure: return empty array (non-critical, matches pipeline pattern)
- Log cost estimate using same token pricing as deepseek.ts

**4. Rewrite `scoreContentAgainstRules()`:**
- Signature change: `async function scoreContentAgainstRules(content: string, rules: Rule[]): Promise<RuleScoreResult>`
- Split rules into two arrays: `regexRules = rules.filter(r => r.evaluation_tier === 'regex')` and `semanticRules = rules.filter(r => r.evaluation_tier === 'semantic')`
- Run regex tier synchronously (existing matchesPattern logic — no changes)
- Run semantic tier via `evaluateSemanticRules(content, semanticRules)`
- Merge results: combine matched_rules from both tiers
- For regex matches, include tier in matched_rule entry:
  ```typescript
  { rule_id: rule.id, rule_name: rule.name, score: evaluation.score, max_score: rule.max_score, tier: 'regex' as const }
  ```
- For semantic results, map each evaluation to a matched_rule entry:
  ```typescript
  { rule_id: rule.id, rule_name: rule.name, score: evaluation.score, max_score: rule.max_score, tier: 'semantic' as const }
  ```
- Scoring formula for final rule_score:
  - Regex matches: same as current (normalized score * weight)
  - Semantic scores: `(evaluation.score / 10) * rule.max_score * rule.weight`
  - Normalize total to 0-100 using totalMaxScore denominator (same as current)
- Return enriched RuleScoreResult with all matched rules from both tiers

**5. Ensure backward compatibility:**
- If all rules are regex tier (no semantic rules), behavior is identical to current
- If DeepSeek semantic eval fails, fall back to regex-only results with a console.warn
- Export signatures don't change — `loadActiveRules` and `scoreContentAgainstRules` are the same

**Important implementation notes:**
- Do NOT import from deepseek.ts (circular dependency risk). Create a local OpenAI client in rules.ts
- Use `deepseek-chat` model for semantic eval (NOT deepseek-reasoner — faster and cheaper for simple evals)
- Rules without a pattern AND without an evaluation_prompt score 0 (skip with log)
- The `evaluation_tier` column defaults to 'regex' in DB, so existing rules work without migration
  </action>
  <verify>
- `pnpm tsc --noEmit` passes (type-check)
- `loadActiveRules` query includes `evaluation_tier` in select
- `scoreContentAgainstRules` splits rules by tier and merges results
- `evaluateSemanticRules` batches rules into single DeepSeek call
- Zod schema validates semantic eval response
- Fallback to regex-only on semantic failure
  </verify>
  <done>
- Rules with evaluation_tier='regex' use matchesPattern (unchanged behavior)
- Rules with evaluation_tier='semantic' use batched DeepSeek evaluation
- Broken rules (loop_structure, emotional_arc, text_overlay) will be evaluated semantically once their DB rows are updated to evaluation_tier='semantic' (Task 2 handles this)
- Failed semantic evaluation falls back gracefully
  </done>
</task>

<task type="auto">
  <name>Task 2: Classify broken rules as semantic tier and verify compilation</name>
  <files>src/lib/engine/rules.ts</files>
  <action>
**1. Document which rules should be semantic tier** by adding a comment block at the top of rules.ts:

```typescript
/**
 * Rule evaluation tier classification:
 *
 * REGEX tier (deterministic, fast, no API cost):
 *   question_hook, curiosity_gap, negative_bias, bold_claim, story_hook,
 *   payoff_delay, pattern_interrupt, info_density, short_duration,
 *   caption_hook, cta_clarity, authenticity
 *
 * SEMANTIC tier (DeepSeek evaluation, slower, ~$0.001 per batch):
 *   loop_structure     — requires video analysis, regex always returns false
 *   emotional_arc      — requires full content analysis, regex always returns false
 *   text_overlay       — regex always returns true (meaningless)
 *   trending_sound     — needs audio context, regex returns false
 *   trending_audio     — needs audio context, regex returns false
 *   original_audio     — no regex pattern, needs semantic eval
 *   post_timing        — no regex pattern, needs semantic eval
 *   content_pacing     — no regex pattern, needs semantic eval
 *   niche_authority    — no regex pattern, needs semantic eval
 *   carousel_depth     — platform-specific, needs semantic eval
 *   thumbnail_bait     — platform-specific, needs semantic eval
 *   duet_stitch        — platform-specific, needs semantic eval
 *   reel_hook_speed    — platform-specific, needs semantic eval
 *
 * NOTE: To switch a rule's tier, update its evaluation_tier column in rule_library.
 * The code reads the tier from DB — no code change needed for reclassification.
 */
```

**2. Create a migration helper comment** in the file noting that the seed data needs `evaluation_tier` updated for the rules listed above. Do NOT create a migration file — the executor for Plan 2 or Plan 3 will handle the DB update if needed. The rules.ts code reads `evaluation_tier` from DB, so no code change is needed to "fix" the broken rules — they just need their DB row updated.

**3. Add a fallback in matchesPattern** for rules that are regex-tier but have no known pattern: instead of the current `default: return false`, log `console.debug('[rules] Unknown regex pattern: ${pattern}')` so broken patterns are visible in logs.

**4. Verify full compilation:**
- Ensure `pnpm tsc --noEmit` passes
- Ensure no import cycles between rules.ts and deepseek.ts
  </action>
  <verify>
- `pnpm tsc --noEmit` passes with zero errors
- Comment block documents which rules belong to which tier
- matchesPattern default case logs unknown patterns
  </verify>
  <done>
- Tier classification documented in code
- Unknown regex patterns logged for debugging
- Full type-check passes
  </done>
</task>

</tasks>

<verification>
1. `pnpm tsc --noEmit` passes — no type errors
2. `loadActiveRules` returns rules with `evaluation_tier` field
3. `scoreContentAgainstRules` handles both tiers:
   - Regex rules: deterministic matching (same as before)
   - Semantic rules: batched DeepSeek evaluation with fallback
4. No circular imports between rules.ts and deepseek.ts
5. Exported function signatures unchanged — pipeline.ts needs no changes
</verification>

<success_criteria>
- Rules engine supports two evaluation tiers (regex and semantic) based on DB column
- Broken rules (loop_structure, emotional_arc, text_overlay) are documented for semantic reclassification
- Semantic evaluation uses single batched DeepSeek call per analysis
- Failed semantic eval falls back gracefully to regex-only
- TypeScript compiles with zero errors
</success_criteria>

<output>
After completion, create `.planning/phases/09-hybrid-rules-dynamic-weights/09-01-SUMMARY.md`
</output>
