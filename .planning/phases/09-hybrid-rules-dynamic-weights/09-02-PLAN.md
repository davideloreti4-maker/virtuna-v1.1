---
phase: 09-hybrid-rules-dynamic-weights
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/engine/rules.ts (matched_rules additions)
  - src/app/api/analyze/route.ts
  - src/app/api/cron/validate-rules/route.ts
autonomous: true

must_haves:
  truths:
    - "Each analysis stores per-rule contributions (rule_id, score, max_score, tier) in DB alongside the result"
    - "Validate-rules cron computes per-rule accuracy from stored contributions vs actual outcomes"
    - "Per-rule accuracy uses exponential moving average (EMA) with alpha=0.3"
    - "Rules with low accuracy get their weight reduced; high accuracy increases weight"
  artifacts:
    - path: "src/app/api/analyze/route.ts"
      provides: "Persists rule_contributions JSONB to analysis_results on each analysis"
    - path: "src/app/api/cron/validate-rules/route.ts"
      provides: "Per-rule accuracy tracking with rule_contributions-based computation"
  key_links:
    - from: "src/app/api/analyze/route.ts"
      to: "analysis_results.rule_contributions"
      via: "DB insert with JSONB column"
      pattern: "rule_contributions.*matched_rules"
    - from: "src/app/api/cron/validate-rules/route.ts"
      to: "analysis_results.rule_contributions"
      via: "DB query for per-rule contribution data"
      pattern: "select.*rule_contributions"
---

<objective>
Implement per-rule accuracy tracking by storing rule_contributions JSONB with each analysis result, then computing per-rule accuracy in the validate-rules cron job from actual outcomes.

Purpose: RULE-03 (per-rule accuracy tracking). Currently the cron uses global MAE — it cannot tell which rules are accurate and which are noise. Per-rule tracking enables evidence-based weight adjustment.

Output: Updated API route + cron with per-rule contribution storage and accuracy computation.
</objective>

<execution_context>
@/Users/davideloreti/.claude/get-shit-done/workflows/execute-plan.md
@/Users/davideloreti/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/app/api/analyze/route.ts
@src/app/api/cron/validate-rules/route.ts
@src/lib/engine/types.ts
@src/lib/engine/aggregator.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Store rule_contributions in analysis_results and compute per-rule accuracy</name>
  <files>src/app/api/analyze/route.ts, src/app/api/cron/validate-rules/route.ts</files>
  <action>
**Part A: Store rule_contributions in API route**

In `src/app/api/analyze/route.ts`, update the DB insert to include `rule_contributions`:

1. After `const result = aggregateScores(pipelineResult);`, extract rule contributions from the pipeline result:

```typescript
// Build rule_contributions JSONB for per-rule tracking (RULE-03)
const ruleContributions = pipelineResult.ruleResult.matched_rules.map(r => ({
  rule_id: r.rule_id,
  rule_name: r.rule_name,
  score: r.score,
  max_score: r.max_score,
}));
```

2. Add `rule_contributions: ruleContributions` to the `.insert({...})` call. The column already exists from Phase 4 migration (`rule_contributions JSONB DEFAULT '{}'`).

**Part B: Rewrite validate-rules cron for per-rule accuracy**

Rewrite `src/app/api/cron/validate-rules/route.ts`:

1. Fetch last 30 days of analysis_results that have both `rule_contributions` (not empty/null) and a matching outcome:

```typescript
// Join analysis_results with outcomes to get predicted vs actual
const { data: resultsWithOutcomes } = await supabase
  .from('analysis_results')
  .select('id, rule_contributions, overall_score, outcomes!inner(actual_score)')
  .not('rule_contributions', 'is', null)
  .gte('created_at', thirtyDaysAgo);
```

If the join syntax doesn't work with Supabase PostgREST, use two separate queries:
- Query 1: Get outcomes with analysis_id from last 30 days
- Query 2: Get analysis_results for those IDs, selecting rule_contributions and overall_score

2. For each active rule, compute per-rule accuracy:

```typescript
interface RuleAccuracyData {
  rule_id: string;
  total_score_contribution: number; // sum of rule scores when rule matched
  total_analyses_with_rule: number; // count of analyses where rule matched
  correct_direction_count: number; // rule score agreed with outcome direction
}
```

For each analysis+outcome pair:
- Extract `rule_contributions` array
- For each rule contribution in the array:
  - Determine if the rule "agreed with outcome": if rule gave high score (>50% of max_score) AND actual_score > predicted_score, OR rule gave low score AND actual_score < predicted_score, count as "correct direction"
  - Simpler approach: compute correlation between rule's normalized score contribution (score/max_score) and prediction accuracy (1 - abs(predicted - actual)/100)

3. For each rule, compute accuracy as:
```
per_rule_accuracy = correct_direction_count / total_analyses_with_rule
```
If `total_analyses_with_rule < 10`, skip update (not enough data for statistical significance).

4. Apply EMA: `new_accuracy = alpha * per_rule_accuracy + (1 - alpha) * prev_accuracy` where `alpha = 0.3`.

5. Adjust weight: `new_weight = max(0.5, min(2.0, 0.5 + new_accuracy * 1.5))` (same formula as current, but now based on per-rule accuracy instead of global).

6. Update each rule's `accuracy_rate`, `sample_count`, and `weight` in DB.

7. Update the response JSON to include per-rule breakdown:
```typescript
{
  processed: validPairs.length,
  rulesUpdated: updatedCount,
  ruleDetails: ruleUpdates.map(r => ({
    name: r.name,
    accuracy: r.accuracy,
    weight: r.weight,
    sample_count: r.sampleCount,
  })),
  skippedRules: skippedCount, // rules with < 10 samples
}
```

**Important notes:**
- The `rule_contributions` column already exists in DB (Phase 4 migration)
- Keep the cron auth check (`verifyCronAuth`) unchanged
- Handle edge cases: empty rule_contributions, null outcomes, zero analyses
  </action>
  <verify>
- `pnpm tsc --noEmit` passes
- API route insert includes `rule_contributions` field
- Cron computes per-rule accuracy from rule_contributions JSONB
- EMA formula with alpha=0.3 applied correctly
- Weight adjustment clamped to 0.5-2.0 range
  </verify>
  <done>
- Each analysis persists rule_contributions JSONB with per-rule scores
- Validate-rules cron computes per-rule accuracy instead of global MAE
- Rules with < 10 samples skipped for stability
- Weight adjustment based on individual rule accuracy, not global average
  </done>
</task>

<task type="auto">
  <name>Task 2: Add evaluation_tier to RuleScoreResult matched_rules for downstream tracking</name>
  <files>src/lib/engine/types.ts</files>
  <action>
Update the `RuleScoreResult` interface's `matched_rules` array to include the evaluation tier, so downstream consumers (API route, cron) know which tier produced each match:

In `src/lib/engine/types.ts`, update:

```typescript
export interface RuleScoreResult {
  rule_score: number; // 0-100
  matched_rules: Array<{
    rule_id: string;
    rule_name: string;
    score: number;
    max_score: number;
    tier: 'regex' | 'semantic'; // NEW: which evaluation path produced this match
  }>;
}
```

This is a minor additive change. The `tier` field will be populated by rules.ts (Plan 01 handles the scoring logic). If Plan 01 hasn't been executed yet, add a temporary `tier: 'regex' as const` in the existing `scoreContentAgainstRules` matched_rules push.

Verify `pnpm tsc --noEmit` passes — the aggregator.ts and pipeline.ts don't access the `tier` field, so adding it is non-breaking.
  </action>
  <verify>
- `pnpm tsc --noEmit` passes
- `RuleScoreResult.matched_rules` includes `tier` field
- No downstream type errors from the addition
  </verify>
  <done>
- RuleScoreResult includes tier field for each matched rule
- API route can persist tier information in rule_contributions JSONB
- TypeScript compiles cleanly
  </done>
</task>

</tasks>

<verification>
1. `pnpm tsc --noEmit` passes — no type errors
2. API route persists `rule_contributions` JSONB to `analysis_results` on every analysis
3. Validate-rules cron reads `rule_contributions` from analysis_results
4. Per-rule accuracy computed from individual rule scores vs outcome direction
5. EMA smoothing with alpha=0.3 prevents wild swings
6. Weight adjustment (0.5-2.0) based on per-rule accuracy
</verification>

<success_criteria>
- Every analysis stores which rules matched and their scores in rule_contributions JSONB
- Cron job computes per-rule accuracy (not global MAE) from stored contributions
- Rules with insufficient data (< 10 samples) are skipped
- Weight adjustments are evidence-based per individual rule performance
- TypeScript compiles with zero errors
</success_criteria>

<output>
After completion, create `.planning/phases/09-hybrid-rules-dynamic-weights/09-02-SUMMARY.md`
</output>
