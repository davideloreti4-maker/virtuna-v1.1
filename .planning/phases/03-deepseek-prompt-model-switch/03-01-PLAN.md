---
phase: 03-deepseek-prompt-model-switch
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/engine/types.ts
  - src/lib/engine/deepseek.ts
autonomous: true

must_haves:
  truths:
    - "DeepSeek uses deepseek-reasoner model (V3.2-reasoning) with OpenAI-compatible API"
    - "DeepSeek output includes behavioral predictions with absolute values AND percentile context"
    - "5-step CoT framework structures internal reasoning (Completion, Share, Pattern, Fatal Flaw, Score)"
    - "Gemini signals passed to DeepSeek WITHOUT numeric scores to prevent anchoring"
    - "Cost estimation uses actual V3.2-reasoning token pricing ($0.28/1M input, $0.42/1M output)"
    - "Dead v1 output fields (variants, conversation_themes) are removed from schema and prompt"
    - "Persona reactions are NOT included in DeepSeek output (deferred to Phase 5/8)"
  artifacts:
    - path: "src/lib/engine/types.ts"
      provides: "DeepSeekResponseSchema v2 with behavioral predictions and component sub-scores"
      contains: "completion_pct"
    - path: "src/lib/engine/deepseek.ts"
      provides: "Rewritten prompt with 5-step CoT, calibration data, Gemini signal handoff, token-based cost"
      contains: "buildDeepSeekPrompt"
  key_links:
    - from: "src/lib/engine/deepseek.ts"
      to: "src/lib/engine/calibration-baseline.json"
      via: "loadCalibrationData() (reuse Gemini's pattern)"
      pattern: "loadCalibrationData"
    - from: "src/lib/engine/deepseek.ts"
      to: "src/lib/engine/types.ts"
      via: "DeepSeekResponseSchema import"
      pattern: "DeepSeekResponseSchema"
---

<objective>
Rewrite DeepSeek's prompt with a structured 5-step chain-of-thought framework, output behavioral predictions (completion_pct, share_pct, comment_pct, save_pct) with percentile context, and update to token-based cost estimation using V3.2-reasoning pricing. Remove dead v1 output fields (variants, conversation_themes, persona_reactions). Pass Gemini signals without numeric scores.

Purpose: DeepSeek becomes a structured behavioral prediction engine that feeds component sub-scores into the Phase 5 aggregator, replacing the v1 approach of a single refined_score with theater outputs.

Output: Updated `types.ts` with DeepSeekResponseSchema v2, rewritten `deepseek.ts` with 5-step CoT prompt and calibration data embedding.
</objective>

<execution_context>
@/Users/davideloreti/.claude/get-shit-done/workflows/execute-plan.md
@/Users/davideloreti/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-deepseek-prompt-model-switch/03-CONTEXT.md
@.planning/phases/02-gemini-prompt-video-analysis/02-01-SUMMARY.md
@src/lib/engine/types.ts
@src/lib/engine/deepseek.ts
@src/lib/engine/gemini.ts
@src/lib/engine/calibration-baseline.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Rewrite DeepSeekResponseSchema v2 with behavioral predictions</name>
  <files>src/lib/engine/types.ts</files>
  <action>
Replace the existing DeepSeekResponseSchema and DeepSeekReasoning type with a v2 schema that outputs:

**New DeepSeekResponseSchema v2 fields:**

1. `behavioral_predictions` — object with:
   - `completion_pct`: number 0-100 (predicted % of viewers who watch to end)
   - `completion_percentile`: string (e.g., "top 30%")
   - `share_pct`: number 0-100 (predicted % of viewers who share)
   - `share_percentile`: string
   - `comment_pct`: number 0-100 (predicted % of viewers who comment)
   - `comment_percentile`: string
   - `save_pct`: number 0-100 (predicted % of viewers who save/bookmark)
   - `save_percentile`: string

2. `component_scores` — object with sub-scores for the Phase 5 aggregator:
   - `hook_effectiveness`: number 0-10 (from CoT Step 1)
   - `retention_strength`: number 0-10 (from CoT Step 1)
   - `shareability`: number 0-10 (from CoT Step 2)
   - `comment_provocation`: number 0-10 (from CoT Step 2)
   - `save_worthiness`: number 0-10 (from CoT Step 2)
   - `trend_alignment`: number 0-10 (from CoT Step 3)
   - `originality`: number 0-10 (from CoT Step 3)

3. `suggestions` — array of objects (keep from v1 but simplified):
   - `text`: string
   - `priority`: "high" | "medium" | "low"
   - `category`: string

4. `warnings` — array of strings (fatal flaws from CoT Step 4, surfaced as high-priority warnings)

5. `confidence` — string ("high" | "medium" | "low") based on signal availability

**Remove from schema:**
- `persona_reactions` (deferred to Phase 5/8 per locked decision)
- `variants` (dead v1 field per locked decision)
- `conversation_themes` (dead v1 field per locked decision)
- `refined_score` (replaced by component_scores for Phase 5 aggregator)
- `confidence_reasoning` (replaced by `confidence` enum)

Also remove the now-unused Zod schemas: `PersonaReactionSchema`, `VariantSchema`, `ConversationThemeSchema`. Keep the TypeScript interfaces `PersonaReaction`, `Variant`, `ConversationTheme` BUT mark them with `@deprecated` JSDoc comments and a note "Remove in Phase 5 cleanup" — other parts of the codebase (aggregator, PredictionResult) still reference them and will be updated in Phase 4/5.

Create a new `BehavioralPredictionsSchema` Zod object and `ComponentScoresSchema` Zod object. Export the types inferred from them.

Update the `DeepSeekReasoning` type alias to point at the new schema.
  </action>
  <verify>Run `npx tsc --noEmit 2>&1 | grep -c "error"` — expect errors only in aggregator.ts or pipeline files that reference old DeepSeek fields (these will be fixed in Phase 5). Zero new errors in types.ts or deepseek.ts.</verify>
  <done>DeepSeekResponseSchema v2 exists with behavioral_predictions, component_scores, suggestions, warnings, and confidence. Old v1-only fields (variants, conversation_themes, persona_reactions, refined_score) removed from schema. Types exported correctly.</done>
</task>

<task type="auto">
  <name>Task 2: Rewrite DeepSeek prompt with 5-step CoT, calibration data, and token-based cost</name>
  <files>src/lib/engine/deepseek.ts</files>
  <action>
Rewrite the `deepseek.ts` module with these changes:

**1. Model configuration:**
- Keep `DEEPSEEK_MODEL = process.env.DEEPSEEK_MODEL ?? "deepseek-reasoner"` — the `deepseek-reasoner` model ID already points to V3.2-reasoning on DeepSeek's API
- Increase `TIMEOUT_MS` from 30s to 45s — reasoning model produces longer outputs with CoT thinking tokens
- Keep circuit breaker, retry logic, and client setup as-is

**2. Token-based cost estimation:**
- Replace the hardcoded `cost_cents = 0.005 * (attempt + 1)` with actual token-based pricing
- V3.2-reasoning pricing: $0.28/1M input tokens, $0.42/1M output tokens
- Extract token counts from `response.usage?.prompt_tokens` and `response.usage?.completion_tokens` (OpenAI SDK format)
- Fallback estimates if usage is unavailable: 3000 input tokens, 2000 output tokens (richer prompt = more tokens)
- Add a `calculateDeepSeekCost()` function following the same pattern as Gemini's `calculateCost()`

**3. Calibration data loading:**
- Import and reuse `loadCalibrationData()` from gemini.ts — BUT gemini.ts doesn't export it currently. Instead, replicate the same pattern: create a `DeepSeekCalibrationData` interface with the fields needed for the prompt, cache the loaded JSON, load from calibration-baseline.json using the same `import.meta.url` + `path.dirname` approach.
- Extract these calibration fields for the prompt:
  - `primary_kpis.share_rate.percentiles` (for behavioral prediction benchmarks)
  - `primary_kpis.comment_rate.percentiles`
  - `primary_kpis.save_rate.percentiles`
  - `primary_kpis.weighted_engagement_score.percentiles`
  - `virality_tiers` (for pattern matching step)
  - `viral_vs_average.differentiators` (for pattern matching step)
  - `duration_analysis.sweet_spot_by_weighted_score`

**4. Gemini signal handoff (prevent anchoring):**
- Update the `DeepSeekInput` interface: the `gemini_analysis` field stays typed as `GeminiAnalysis` but when building the prompt, extract ONLY:
  - Factor names and rationales (NOT scores)
  - Improvement tips
  - Overall impression
  - Content summary
  - Video signals descriptions (if available): "Visual production: [rationale]", "Hook impact: [rationale]", etc.
- Create a `formatGeminiSignals(analysis: GeminiAnalysis)` helper that strips scores and formats the signals as text

**5. Rewrite the prompt with 5-step CoT:**

Replace `REASONING_PROMPT` with a `buildDeepSeekPrompt()` function (following Gemini's prompt-as-function pattern) that takes `DeepSeekInput` + calibration data and returns the full prompt.

The prompt must instruct the model to reason through 5 steps internally:

```
## Your Task

You are an expert TikTok content strategist. Analyze the content below using the 5-step framework. Your reasoning is INTERNAL — the user only sees your final JSON output.

## 5-Step Reasoning Framework

### Step 1: Completion Analysis
Evaluate: Would viewers watch this to the end?
Consider: Hook strength, narrative tension, pacing, payoff anticipation, information drip.
Output: hook_effectiveness (0-10), retention_strength (0-10), completion_pct prediction.

### Step 2: Engagement Prediction
Evaluate: Would viewers take action?
Consider: Share triggers (relatability, identity signaling, "tag someone"), comment provocation (controversy, questions, relatable frustrations), save worthiness (reference value, tutorial quality, bookmark-worthy tips).
Output: shareability (0-10), comment_provocation (0-10), save_worthiness (0-10), share_pct/comment_pct/save_pct predictions.

### Step 3: Pattern Match
Compare this content against known viral patterns from the dataset:
- Loop structure (videos that naturally restart)
- Duet/stitch bait (content that invites responses)
- Trending sound alignment
- Hook-first structure (value in first 3 seconds)
- Emotional escalation pattern
- "Wait for it" payoff structure
[Embed top 5 viral differentiators from calibration data here]
Output: trend_alignment (0-10), originality (0-10).

### Step 4: Fatal Flaw Check
Identify any critical issues that would kill performance regardless of other factors:
- No clear hook in first 2 seconds
- Content too long for topic (>60s for simple content)
- Misleading hook that doesn't pay off
- Poor audio quality or no audio strategy
- Caption too long (>100 chars for non-educational content)
- Content that actively discourages sharing (controversial without being shareable)
Output: Array of warning strings (empty if no fatal flaws).

### Step 5: Final Scores & Predictions
Using steps 1-4, produce your final behavioral predictions with percentile context.
Reference these dataset benchmarks for percentile framing:
- Share rate: p50={share_p50}, p75={share_p75}, p90={share_p90}
- Comment rate: p50={comment_p50}, p75={comment_p75}, p90={comment_p90}
- Save rate: p50={save_p50}, p75={save_p75}, p90={save_p90}
Frame percentiles as "top X%" (e.g., p90 = "top 10%", p75 = "top 25%").
```

After the framework, include:
- The content text and type
- Gemini's analysis (formatted via `formatGeminiSignals()` — rationales and tips only, NO scores)
- Rule match context (rule names that matched, NOT rule scores)
- Trend context string
- 3-5 actionable suggestions

**6. Update `reasonWithDeepSeek()` function:**
- Keep the same function signature and return type shape, but update `DeepSeekReasoning` to match the new schema
- Use `response_format: { type: "json_object" }` (already present)
- Parse with the new `DeepSeekResponseSchema`
- Calculate cost with the new `calculateDeepSeekCost()` function
- Add soft cost cap warning at 1.0 cents (V3.2 reasoning with rich prompts)

**7. Remove dead code:**
- Remove the `stripThinkTags()` function — V3.2 reasoning uses the `reasoning_content` field in the response object, not inline `<think>` tags. The JSON output in `message.content` is already clean.
  </action>
  <verify>
1. `npx tsc --noEmit 2>&1 | grep "deepseek.ts"` — zero type errors in deepseek.ts
2. Verify the prompt contains all 5 CoT steps by searching for "Step 1", "Step 2", etc.
3. Verify calibration data references are present (share_rate, comment_rate, save_rate percentiles)
4. Verify Gemini signals are formatted without scores (no `score:` in the formatted output)
5. Verify cost uses $0.28/1M and $0.42/1M pricing constants
  </verify>
  <done>
- DeepSeek uses deepseek-reasoner model (V3.2-reasoning) with structured 5-step CoT prompt
- Behavioral predictions (completion_pct, share_pct, comment_pct, save_pct) with percentile context in output
- Gemini signals passed without numeric scores (rationales and tips only)
- Calibration data from 7,321 videos embedded in prompt (share/comment/save rate percentiles, viral differentiators)
- Token-based cost estimation at $0.28/1M input, $0.42/1M output
- Dead v1 code (stripThinkTags, hardcoded cost) removed
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` — expect zero errors in types.ts and deepseek.ts (aggregator.ts errors from Phase 2 are expected and will be fixed in Phase 5)
2. DeepSeekResponseSchema v2 validates a sample object with behavioral_predictions, component_scores, suggestions, warnings, confidence
3. No `refined_score`, `variants`, `conversation_themes`, or `persona_reactions` in DeepSeekResponseSchema
4. Prompt embeds real calibration percentiles from calibration-baseline.json
5. Gemini analysis is formatted without numeric scores
6. Cost calculation uses V3.2 pricing constants
</verification>

<success_criteria>
- DeepSeek module uses deepseek-reasoner (V3.2-reasoning) with 5-step CoT framework
- Output schema includes behavioral predictions with absolute values AND percentile context
- Component sub-scores ready for Phase 5 aggregation formula
- Gemini signals passed without numeric scores to prevent anchoring
- Cost estimation is token-based with V3.2 pricing
- Dead v1 fields removed from schema, dead code removed from implementation
</success_criteria>

<output>
After completion, create `.planning/phases/03-deepseek-prompt-model-switch/03-01-SUMMARY.md`
</output>
