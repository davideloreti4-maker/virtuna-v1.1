---
phase: 01-schedule-crons-fix-data-pipeline-wiring
plan: 02
type: execute
wave: 2
depends_on: ["01"]
files_modified:
  - .env.example
  - src/app/api/cron/scrape-trending/route.ts
  - src/app/api/webhooks/apify/route.ts
  - src/app/api/cron/calculate-trends/route.ts
  - src/app/api/cron/sync-whop/route.ts
autonomous: true

must_haves:
  truths:
    - "scrape-trending cron triggers Apify actor with webhook callback pointing to /api/webhooks/apify"
    - "Apify webhook handler receives payload, fetches dataset, and upserts rows into scraped_videos"
    - "calculate-trends cron reads from scraped_videos and writes aggregated data to trending_sounds"
    - "All 17 env vars are documented in .env.example with descriptions and source hints"
  artifacts:
    - path: ".env.example"
      provides: "Complete environment variable documentation for developer onboarding"
      contains: "APIFY_TOKEN"
    - path: "src/app/api/cron/scrape-trending/route.ts"
      provides: "Apify actor trigger with webhook registration"
      exports: ["GET"]
    - path: "src/app/api/webhooks/apify/route.ts"
      provides: "Apify completion webhook handler — dataset fetch and DB upsert"
      exports: ["POST"]
    - path: "src/app/api/cron/calculate-trends/route.ts"
      provides: "scraped_videos aggregation into trending_sounds"
      exports: ["GET"]
  key_links:
    - from: "src/app/api/cron/scrape-trending/route.ts"
      to: "src/app/api/webhooks/apify/route.ts"
      via: "Apify webhook callback URL using NEXT_PUBLIC_APP_URL"
      pattern: "NEXT_PUBLIC_APP_URL.*webhooks/apify"
    - from: "src/app/api/webhooks/apify/route.ts"
      to: "supabase scraped_videos table"
      via: "service role client upsert with onConflict"
      pattern: "upsert.*scraped_videos"
    - from: "src/app/api/cron/calculate-trends/route.ts"
      to: "supabase scraped_videos -> trending_sounds"
      via: "SELECT from scraped_videos, upsert into trending_sounds"
      pattern: "scraped_videos.*trending_sounds"
---

<objective>
Trace and verify the end-to-end scrape pipeline chain, fix any bugs found, normalize auth inconsistencies, and document all environment variables.

Purpose: The pipeline (scrape-trending -> webhook -> scraped_videos -> calculate-trends -> trending_sounds) is the foundation of the prediction engine. Verifying it works end-to-end ensures Phase 2+ have real data to work with. Complete env var documentation enables any developer to set up the project.

Output: Verified pipeline chain (with any bugs fixed), normalized cron auth, and comprehensive .env.example file.
</objective>

<execution_context>
@/Users/davideloreti/.claude/get-shit-done/workflows/execute-plan.md
@/Users/davideloreti/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-schedule-crons-fix-data-pipeline-wiring/01-01-SUMMARY.md
@src/app/api/cron/scrape-trending/route.ts
@src/app/api/webhooks/apify/route.ts
@src/app/api/cron/calculate-trends/route.ts
@src/app/api/cron/sync-whop/route.ts
@src/lib/cron-auth.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Trace and verify scrape pipeline chain end-to-end</name>
  <files>src/app/api/cron/scrape-trending/route.ts, src/app/api/webhooks/apify/route.ts, src/app/api/cron/calculate-trends/route.ts, src/app/api/cron/sync-whop/route.ts, src/lib/cron-auth.ts</files>
  <action>
**Read and trace the full chain. For each handler, verify the contract between stages:**

**Stage 1 — scrape-trending/route.ts:**
- Verify: imports and uses `verifyCronAuth(request)` for auth
- Verify: calls `client.actor(APIFY_ACTOR_ID).start()` (NOT `.call()` — must be non-blocking)
- Verify: webhook URL is `${process.env.NEXT_PUBLIC_APP_URL}/api/webhooks/apify`
- Verify: `payloadTemplate` uses `{{resource}}` and `{{eventType}}` (Apify template vars, double braces)
- Verify: `APIFY_WEBHOOK_SECRET` is included in payload template as `"secret"` field
- Verify: hashtags are included in payload (needed for tracking which scrape produced which data)
- Check: `maxDuration` export exists if handler might exceed default timeout

**Stage 2 — webhooks/apify/route.ts:**
- Verify: POST handler (not GET)
- Verify: validates `payload.secret` against `APIFY_WEBHOOK_SECRET`
- Verify: extracts `resource.defaultDatasetId` from Apify callback payload
- Verify: fetches dataset via `client.dataset(datasetId).listItems()`
- Verify: maps Apify video fields to `scraped_videos` columns correctly (platform_video_id, views, likes, shares, comments, sound_name, sound_url, hashtags as TEXT[], etc.)
- Verify: upserts with `onConflict: "platform,platform_video_id"` (prevents duplicates)
- Verify: batch size is reasonable (50 per upsert per research)
- Check: error handling — does a failed upsert batch skip or abort?

**Stage 3 — calculate-trends/route.ts:**
- Verify: imports and uses `verifyCronAuth(request)` for auth
- Verify: reads from `scraped_videos` with `archived_at IS NULL` filter and time window (48h per research)
- Verify: aggregates by `sound_name` (video_count, total_views, growth_rate, velocity_score)
- Verify: classifies `trend_phase` (emerging/rising/peak/declining)
- Verify: upserts into `trending_sounds` with `onConflict: "sound_name"`

**Stage 4 — sync-whop auth normalization:**
- Read `sync-whop/route.ts` and `src/lib/cron-auth.ts`
- Replace inline auth check in sync-whop with `verifyCronAuth(request)` call (import from `@/lib/cron-auth`)
- This normalizes all 7 cron routes to use the same auth pattern

**If any bug is found during tracing:** Fix it in-place. Document what was found and fixed.
**If no bugs found:** Document that the chain is verified correct as-is.

After any changes, run `pnpm build` to confirm no regressions.
  </action>
  <verify>
1. `grep -n "verifyCronAuth" src/app/api/cron/sync-whop/route.ts` confirms shared auth helper is used
2. `grep -n "actor.*start" src/app/api/cron/scrape-trending/route.ts` confirms non-blocking actor start
3. `grep -n "onConflict" src/app/api/webhooks/apify/route.ts` confirms upsert dedup
4. `grep -n "trending_sounds" src/app/api/cron/calculate-trends/route.ts` confirms write target
5. `pnpm build` exits with code 0
6. Runtime evidence for webhook handler: `curl -s -o /dev/null -w "%{http_code}" -X POST http://localhost:3000/api/webhooks/apify -H "Content-Type: application/json" -d '{"resource":{"defaultDatasetId":"test"},"eventType":"ACTOR.RUN.SUCCEEDED","secret":"test"}'` — expect 401 or 403 (secret mismatch proves the handler is reachable and validates auth). If the dev server is not running, note this explicitly: "Runtime webhook test deferred to post-deployment smoke test — handler structure verified via code review."
  </verify>
  <done>Full scrape-trending -> webhook/apify -> scraped_videos -> calculate-trends -> trending_sounds chain verified correct. sync-whop uses shared verifyCronAuth. Build passes. Webhook handler reachability confirmed via curl (or explicitly deferred to post-deployment smoke test with documented reason).</done>
</task>

<task type="auto">
  <name>Task 2: Create comprehensive .env.example with all env vars</name>
  <files>.env.example</files>
  <action>
Create `.env.example` at the repo root documenting all 17 environment variables found in the codebase. Group by service with clear section headers, descriptions, and source hints.

**Structure:**

```
# Supabase
NEXT_PUBLIC_SUPABASE_URL=       # Project URL from supabase.com/dashboard → Settings → API
NEXT_PUBLIC_SUPABASE_ANON_KEY=  # Anon/public key from same page
SUPABASE_SERVICE_ROLE_KEY=      # Service role key (secret — never expose client-side)

# App URL
NEXT_PUBLIC_APP_URL=            # Production URL (e.g. https://your-app.vercel.app) — used for webhook callbacks

# Vercel Cron Authentication
CRON_SECRET=                    # Random 16+ char string — Vercel sends as Authorization: Bearer header

# Apify (TikTok Scraping)
APIFY_TOKEN=                    # API token from console.apify.com → Account → Integrations
APIFY_WEBHOOK_SECRET=           # Shared secret for webhook payload verification (you create this)
APIFY_ACTOR_ID=                 # Actor ID (default: clockworks~tiktok-scraper)
SCRAPER_HASHTAGS=               # Comma-separated hashtags (default: trending,viral,fyp,comedy,dance,cooking,fitness,fashion,beauty,tech,education,storytelling,lifehack,motivation)

# AI / LLM
GEMINI_API_KEY=                 # Google AI Studio → API keys
GEMINI_MODEL=                   # Optional (default: gemini-2.5-flash)
DEEPSEEK_API_KEY=               # DeepSeek platform → API keys
DEEPSEEK_MODEL=                 # Optional (default: deepseek-reasoner)

# Whop (Payments)
WHOP_API_KEY=                   # Whop dashboard → Developer settings
WHOP_WEBHOOK_SECRET=            # Webhook signing secret from Whop
WHOP_PRODUCT_ID_STARTER=        # Product ID for Starter tier
WHOP_PRODUCT_ID_PRO=            # Product ID for Pro tier
```

For each var, include:
- Inline comment explaining what it is and where to get it
- Mark optional vars with "(optional)" and note defaults
- Group logically by service

Do NOT include actual secret values. Use empty values or descriptive placeholders.

If `.env.local.example` already exists in the repo, check its contents first. If it has useful content, migrate it to `.env.example` and note the old file as superseded (but don't delete it — just note in the new file).
  </action>
  <verify>
1. `.env.example` exists at repo root
2. `grep -c "=" .env.example` returns >= 17 (at least 17 variables documented)
3. `grep "APIFY_TOKEN" .env.example` confirms Apify vars are present
4. `grep "CRON_SECRET" .env.example` confirms cron auth var is documented
5. `grep "WHOP_API_KEY" .env.example` confirms Whop vars are present
  </verify>
  <done>.env.example at repo root documents all 17 env vars with descriptions, grouped by service, with source hints for obtaining values.</done>
</task>

</tasks>

<verification>
1. Pipeline chain verified: scrape-trending -> webhook/apify -> scraped_videos -> calculate-trends -> trending_sounds (no broken links)
2. All cron routes use `verifyCronAuth()` (including sync-whop after normalization)
3. `.env.example` documents all 17 env vars with service grouping and source hints
4. `pnpm build` succeeds
</verification>

<success_criteria>
- End-to-end pipeline chain verified correct (or bugs found and fixed)
- sync-whop auth normalized to use shared verifyCronAuth helper
- .env.example documents all 17 env vars grouped by service
- Build passes
</success_criteria>

<output>
After completion, create `.planning/phases/01-schedule-crons-fix-data-pipeline-wiring/01-02-SUMMARY.md`
</output>
