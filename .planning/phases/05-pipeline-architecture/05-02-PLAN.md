---
phase: 05-pipeline-architecture
plan: 02
type: execute
wave: 2
depends_on: ["05-01"]
files_modified:
  - src/lib/engine/aggregator.ts
  - src/app/api/analyze/route.ts
  - src/hooks/queries/use-analyze.ts
autonomous: true

must_haves:
  truths:
    - "Aggregation formula applies: behavioral 45% + gemini 25% + rules 20% + trends 10%"
    - "Gemini factor scores contribute 25% to final prediction score"
    - "Confidence is a numeric 0-1 value based on signal availability and model agreement"
    - "Per-component score breakdown included in result (behavioral contributed X, gemini Y, etc.)"
    - "Per-run API cost (Gemini + DeepSeek tokens) tracked in result"
    - "Low confidence triggers a warning message"
    - "FeatureVector assembled from all stage outputs"
  artifacts:
    - path: "src/lib/engine/aggregator.ts"
      provides: "New aggregation formula, confidence calculation, FeatureVector assembly"
      exports: ["aggregateScores", "ENGINE_VERSION"]
    - path: "src/app/api/analyze/route.ts"
      provides: "API route wired to new pipeline + aggregator, v2 DB insert"
      exports: ["POST"]
    - path: "src/hooks/queries/use-analyze.ts"
      provides: "Client hook with updated SSE phase names"
      exports: ["useAnalyze", "useAnalysisHistory"]
  key_links:
    - from: "src/app/api/analyze/route.ts"
      to: "src/lib/engine/pipeline.ts"
      via: "runPredictionPipeline() call"
      pattern: "runPredictionPipeline"
    - from: "src/app/api/analyze/route.ts"
      to: "src/lib/engine/aggregator.ts"
      via: "aggregateScores() with PipelineResult"
      pattern: "aggregateScores"
    - from: "src/lib/engine/aggregator.ts"
      to: "src/lib/engine/types.ts"
      via: "FeatureVector, PredictionResult, BehavioralPredictions types"
      pattern: "FeatureVector.*PredictionResult"
---

<objective>
Implement the new aggregation formula and wire the restructured pipeline into the API route and client hook.

Purpose: The current aggregator uses v1 weights (rule 50% + trend 30% + ml 20%) and ignores Gemini scores entirely. This plan implements the v2 formula (behavioral 45% + gemini 25% + rules 20% + trends 10%), adds a real confidence calculation, assembles the FeatureVector, and updates the API route to use the new pipeline output.

Output: Rewritten `aggregator.ts`, updated `route.ts`, and updated `use-analyze.ts`.
</objective>

<execution_context>
@/Users/davideloreti/.claude/get-shit-done/workflows/execute-plan.md
@/Users/davideloreti/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-pipeline-architecture/05-01-SUMMARY.md

# Key source files to read before implementing
@src/lib/engine/aggregator.ts
@src/lib/engine/types.ts
@src/lib/engine/pipeline.ts
@src/app/api/analyze/route.ts
@src/hooks/queries/use-analyze.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Rewrite aggregator with v2 formula, confidence, and FeatureVector assembly</name>
  <files>src/lib/engine/aggregator.ts</files>
  <action>
Completely rewrite `src/lib/engine/aggregator.ts`. The current file uses v1 weights, references dead fields (persona_reactions, variants, conversation_themes, refined_score, description, tips), and produces a v1 PredictionResult shape. Replace entirely.

**Score weights (config-driven for maintainability):**
```typescript
const SCORE_WEIGHTS = {
  behavioral: 0.45,
  gemini: 0.25,
  rules: 0.20,
  trends: 0.10,
} as const;
```

**aggregateScores function signature:**
```typescript
import type { PipelineResult, StageTiming } from "./pipeline";
import type { CreatorContext } from "./creator";

export function aggregateScores(
  pipelineResult: PipelineResult
): PredictionResult
```

Takes the full `PipelineResult` from the pipeline and returns a `PredictionResult`.

**Behavioral score (45% weight):**
- Source: DeepSeek's `component_scores` (7 sub-scores, each 0-10)
- Calculate average of all 7 component scores: `(hook_effectiveness + retention_strength + shareability + comment_provocation + save_worthiness + trend_alignment + originality) / 7`
- Normalize to 0-100: `avg * 10`
- This gives `behavioral_score` (0-100)

**Gemini score (25% weight):**
- Source: Gemini's 5 factor scores (each 0-10)
- Calculate average: `(factors[0].score + ... + factors[4].score) / 5`
- Normalize to 0-100: `avg * 10`
- This gives `gemini_score` (0-100)

**Rules score (20% weight):**
- Source: `ruleResult.rule_score` — already 0-100

**Trends score (10% weight):**
- Source: `trendEnrichment.trend_score` — already 0-100

**Overall score:**
```typescript
const overall_score = Math.round(
  behavioral_score * SCORE_WEIGHTS.behavioral +
  gemini_score * SCORE_WEIGHTS.gemini +
  ruleResult.rule_score * SCORE_WEIGHTS.rules +
  trendEnrichment.trend_score * SCORE_WEIGHTS.trends
);
```
Clamp to 0-100.

**Confidence calculation (user decision: signal availability + model agreement):**
```typescript
function calculateConfidence(
  geminiScore: number,      // 0-100
  behavioralScore: number,  // 0-100
  ruleResult: RuleScoreResult,
  trendEnrichment: TrendEnrichment,
  hasVideo: boolean,
  deepseekConfidence: "high" | "medium" | "low"
): { confidence: number; confidence_label: ConfidenceLevel }
```

Signal availability component (0-0.6):
- Base: 0.2 (always have text)
- +0.1 if video present (hasVideo)
- +0.1 if trends matched (matched_trends.length > 0)
- +0.1 if 3+ rules matched
- +0.1 if DeepSeek confidence is "high" (else +0.05 for "medium")

Model agreement component (0-0.4):
- Calculate direction agreement between Gemini and DeepSeek: both models should push the score in the same direction relative to 50 (midpoint).
- `geminiDirection = geminiScore - 50` and `behavioralDirection = behavioralScore - 50`
- If same sign (both above or both below 50): agreement = 0.4
- If different signs but within 15 points of each other: agreement = 0.2
- If different signs and far apart: agreement = 0.0

Total confidence = signal + agreement, clamped to 0-1.
- confidence_label: >= 0.7 = "HIGH", >= 0.4 = "MEDIUM", < 0.4 = "LOW"

**Low confidence warning (user decision):**
If confidence < 0.4, append "Low confidence — limited signal data" to the warnings array.

**FeatureVector assembly:**
Build the complete FeatureVector from all stage outputs:
```typescript
const feature_vector: FeatureVector = {
  // Gemini factors (map by name)
  hookScore: findFactor("Scroll-Stop Power")?.score ?? 0,
  completionPull: findFactor("Completion Pull")?.score ?? 0,
  rewatchPotential: findFactor("Rewatch Potential")?.score ?? 0,
  shareTrigger: findFactor("Share Trigger")?.score ?? 0,
  emotionalCharge: findFactor("Emotional Charge")?.score ?? 0,

  // Video signals (null if no video)
  visualProductionQuality: gemini.video_signals?.visual_production_quality ?? null,
  hookVisualImpact: gemini.video_signals?.hook_visual_impact ?? null,
  pacingScore: gemini.video_signals?.pacing_score ?? null,
  transitionQuality: gemini.video_signals?.transition_quality ?? null,

  // DeepSeek component scores
  hookEffectiveness: deepseek?.component_scores.hook_effectiveness ?? 0,
  retentionStrength: deepseek?.component_scores.retention_strength ?? 0,
  shareability: deepseek?.component_scores.shareability ?? 0,
  commentProvocation: deepseek?.component_scores.comment_provocation ?? 0,
  saveWorthiness: deepseek?.component_scores.save_worthiness ?? 0,
  trendAlignment: deepseek?.component_scores.trend_alignment ?? 0,
  originality: deepseek?.component_scores.originality ?? 0,

  // Rules and trends
  ruleScore: ruleResult.rule_score,
  trendScore: trendEnrichment.trend_score,

  // Audio (placeholder — Phase 11)
  audioTrendingMatch: null,

  // Caption/Hashtag
  captionScore: 0, // Placeholder — populated in Phase 9
  hashtagRelevance: 0, // Placeholder — populated in Phase 11
  hashtagCount: payload.hashtags.length,

  // Content metadata
  durationSeconds: payload.duration_hint,
  hasVideo: payload.input_mode !== "text",
};
```

**Per-component score breakdown:**
Include in the result for transparency (user decision):
- `behavioral_score`: the computed behavioral score (0-100)
- `gemini_score`: the computed gemini score (0-100)
- `rule_score`: from rules
- `trend_score`: from trends
- `score_weights`: the weight object

**Cost tracking:**
```typescript
const cost_cents = geminiResult.cost_cents + (deepseekResult?.cost_cents ?? 0);
```
Round to 4 decimal places.

**Factors mapping:**
Map Gemini factors to the v2 Factor type (rationale/improvement_tip, NOT description/tips):
```typescript
const factors: Factor[] = geminiAnalysis.factors.map((f, i) => ({
  id: `factor-${i + 1}`,
  name: f.name,
  score: f.score,
  max_score: 10,
  rationale: f.rationale,
  improvement_tip: f.improvement_tip,
}));
```

**Suggestions:**
From DeepSeek (already has id/text/priority/category shape). Add `id` prefix:
```typescript
const suggestions: Suggestion[] = deepseek.suggestions.map((s, i) => ({
  id: `suggestion-${i + 1}`,
  ...s,
}));
```

**Full PredictionResult assembly:**
Return a PredictionResult matching the v2 interface from types.ts:
```typescript
return {
  overall_score,
  confidence: conf.confidence,
  confidence_label: conf.confidence_label,
  behavioral_predictions: deepseek.behavioral_predictions,
  feature_vector,
  reasoning: "", // DeepSeek reasoning text — not exposed in current schema, set empty
  warnings: [...(deepseek?.warnings ?? []), ...(conf.confidence < 0.4 ? ["Low confidence — limited signal data"] : [])],
  factors,
  suggestions,
  rule_score: ruleResult.rule_score,
  trend_score: trendEnrichment.trend_score,
  gemini_score,
  behavioral_score,
  score_weights: SCORE_WEIGHTS,
  latency_ms: pipelineResult.total_duration_ms,
  cost_cents,
  engine_version: ENGINE_VERSION,
  gemini_model: GEMINI_MODEL,
  deepseek_model: deepseekResult ? DEEPSEEK_MODEL : null,
  input_mode: pipelineResult.payload.input_mode,
  has_video: pipelineResult.payload.input_mode !== "text",
};
```

**Remove all v1 dead code:**
- Delete `mapGeminiFactors` (references `f.description`, `f.tips`)
- Delete persona_reactions, variants, conversation_themes fallbacks
- Delete `SCORE_WEIGHTS = { rule: 0.5, trend: 0.3, ml: 0.2 }`
- Delete `ml_score` / `refined_score` references
- Update ENGINE_VERSION to `"2.0.0"`
  </action>
  <verify>
Run `npx tsc --noEmit --skipLibCheck` — zero errors. Verify aggregator exports `aggregateScores` and `ENGINE_VERSION`. Confirm no references to `description`, `tips`, `persona_reactions`, `variants`, `conversation_themes`, `refined_score`, `ml_score` remain.
  </verify>
  <done>
aggregator.ts uses v2 formula (behavioral 45% + gemini 25% + rules 20% + trends 10%), produces numeric confidence based on signal availability + model agreement, assembles full FeatureVector, includes per-component breakdown, tracks per-run cost, and adds low-confidence warning.
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire pipeline into API route and update client hook</name>
  <files>src/app/api/analyze/route.ts, src/hooks/queries/use-analyze.ts</files>
  <action>
**Update `src/app/api/analyze/route.ts`:**

The current route duplicates the pipeline logic inline (calls Gemini, rules, trends, DeepSeek directly). Replace with a call to `runPredictionPipeline()` + `aggregateScores()`.

Key changes:
1. Import `runPredictionPipeline` from `@/lib/engine/pipeline` and `aggregateScores` from `@/lib/engine/aggregator`
2. Remove direct imports of `analyzeWithGemini`, `reasonWithDeepSeek`, `loadActiveRules`, `scoreContentAgainstRules`, `enrichWithTrends`
3. The SSE stream structure stays the same (per user decision: SSE streams final result only, loading UI uses timed phases)
4. Update SSE phase messages to match new pipeline stage names:
   - Phase 1: "analyzing" — "Analyzing content with Gemini and loading creator context..."
   - Phase 2: "reasoning" — "Running DeepSeek reasoning and trend analysis..."
   - Phase 3: "scoring" — "Calculating predictions and assembling results..."
5. Inside the stream:
   ```typescript
   // Phase 1: Run pipeline
   send("phase", { phase: "analyzing", message: "Analyzing content with Gemini and loading creator context..." });
   const pipelineResult = await runPredictionPipeline(validated);

   // Phase 2: Aggregate
   send("phase", { phase: "scoring", message: "Calculating predictions and assembling results..." });
   const result = aggregateScores(pipelineResult);
   ```
   Note: The pipeline now handles the internal Wave 1/Wave 2 orchestration. The route just calls the pipeline and then aggregates. We keep SSE phases for the loading UI, but they're simpler now — the pipeline is a single call.

6. **Update DB insert for v2 columns:**
   The current insert uses v1 fields. Update to v2:
   ```typescript
   await service.from("analysis_results").insert({
     user_id: user.id,
     content_text: validated.content_text ?? "",
     content_type: validated.content_type,
     society_id: validated.society_id ?? null,
     overall_score: result.overall_score,
     confidence: result.confidence, // Now numeric 0-1 (was categorical string)
     factors: result.factors as unknown as null,
     suggestions: result.suggestions as unknown as null,
     rule_score: result.rule_score,
     trend_score: result.trend_score,
     score_weights: result.score_weights as unknown as null,
     latency_ms: result.latency_ms,
     cost_cents: result.cost_cents,
     engine_version: result.engine_version,
     gemini_model: result.gemini_model,
     deepseek_model: result.deepseek_model,
     // v2 columns (from Phase 4 migration)
     behavioral_predictions: result.behavioral_predictions as unknown as null,
     feature_vector: result.feature_vector as unknown as null,
     reasoning: result.reasoning,
     warnings: result.warnings,
     input_mode: result.input_mode,
     has_video: result.has_video,
     gemini_score: result.gemini_score,
   });
   ```
   Remove: `personas`, `variants`, `conversation_themes`, `ml_score` columns (these were v1).

7. **Error handling:**
   The pipeline now throws specific errors (e.g., "Analysis failed: Gemini content analysis — ..."). The catch block in the SSE stream already catches these and sends them as error events. The error messages will now be stage-specific per user decision.

**Update `src/hooks/queries/use-analyze.ts`:**

Minimal changes — the hook already handles SSE correctly. Update:
1. The `AnalysisPhase` type to include new phase names:
   ```typescript
   type AnalysisPhase =
     | "idle"
     | "analyzing"
     | "reasoning"
     | "scoring"
     | "complete"
     | "error";
   ```
   Remove "matching", "simulating", "generating" — these were v1 phases.

2. The mutation input type to accept v2 AnalysisInput fields:
   ```typescript
   mutationFn: async (input: {
     input_mode: "text" | "tiktok_url" | "video_upload";
     content_text?: string;
     content_type: string;
     tiktok_url?: string;
     video_storage_path?: string;
     society_id?: string;
     niche?: string;
     creator_handle?: string;
   }) => { ... }
   ```
   This matches the AnalysisInput schema from types.ts. The actual validation happens server-side.
  </action>
  <verify>
Run `npx tsc --noEmit --skipLibCheck` — zero errors. Verify route.ts imports runPredictionPipeline and aggregateScores. Verify use-analyze.ts has updated phase types. Confirm no references to `analyzeWithGemini`, `reasonWithDeepSeek`, `loadActiveRules`, `scoreContentAgainstRules`, `enrichWithTrends` remain in route.ts.
  </verify>
  <done>
API route wired to new pipeline + aggregator, DB insert uses v2 columns (behavioral_predictions, feature_vector, reasoning, warnings, input_mode, has_video, gemini_score), old v1 columns removed. Client hook has updated phase names and v2 input type.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit --skipLibCheck` passes with zero errors across all modified files
2. aggregator.ts uses v2 weights (0.45/0.25/0.20/0.10) — no references to v1 weights (0.5/0.3/0.2)
3. No references to `persona_reactions`, `variants`, `conversation_themes`, `refined_score`, `ml_score` in aggregator.ts or route.ts
4. route.ts calls `runPredictionPipeline()` then `aggregateScores()` — no direct engine module calls
5. DB insert includes v2 columns: behavioral_predictions, feature_vector, reasoning, warnings, input_mode, has_video, gemini_score
6. use-analyze.ts phase type matches new SSE phase names
7. Confidence is numeric 0-1 with "LOW" label triggering warning
</verification>

<success_criteria>
- Overall score uses v2 aggregation: behavioral 45% + gemini 25% + rules 20% + trends 10%
- Gemini factors contribute 25% to the overall score (fixed from 0% in v1)
- Confidence is numeric 0-1 based on signal availability AND model agreement direction
- FeatureVector populated from all stage outputs
- Per-component score breakdown in result (behavioral_score, gemini_score, rule_score, trend_score)
- Per-run cost_cents includes both Gemini and DeepSeek token costs
- API route uses pipeline + aggregator pattern, not direct engine calls
- DB insert writes v2 columns
</success_criteria>

<output>
After completion, create `.planning/phases/05-pipeline-architecture/05-02-SUMMARY.md`
</output>
