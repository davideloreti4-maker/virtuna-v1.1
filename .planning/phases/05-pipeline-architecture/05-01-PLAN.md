---
phase: 05-pipeline-architecture
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/engine/creator.ts
  - src/lib/engine/pipeline.ts
autonomous: true

must_haves:
  truths:
    - "Pipeline runs 10 stages in Wave 1 (Gemini + Audio + Creator parallel) and Wave 2 (DeepSeek + Trends parallel)"
    - "Creator Context queries creator_profiles and returns engagement baseline (or platform-wide averages as cold start)"
    - "If any stage fails, the entire analysis fails with a specific error identifying which stage failed"
    - "Per-stage execution timing is captured for every pipeline run"
  artifacts:
    - path: "src/lib/engine/creator.ts"
      provides: "Creator Context stage — queries creator_profiles, cold start from scraped_videos"
      exports: ["fetchCreatorContext", "CreatorContext"]
    - path: "src/lib/engine/pipeline.ts"
      provides: "10-stage pipeline with wave parallelism and strict failure mode"
      exports: ["runPredictionPipeline"]
  key_links:
    - from: "src/lib/engine/pipeline.ts"
      to: "src/lib/engine/creator.ts"
      via: "fetchCreatorContext() call in Wave 1"
      pattern: "fetchCreatorContext"
    - from: "src/lib/engine/pipeline.ts"
      to: "src/lib/engine/normalize.ts"
      via: "normalizeInput() as pipeline entry point"
      pattern: "normalizeInput"
    - from: "src/lib/engine/pipeline.ts"
      to: "src/lib/engine/gemini.ts"
      via: "analyzeWithGemini() in Wave 1"
      pattern: "analyzeWithGemini"
    - from: "src/lib/engine/pipeline.ts"
      to: "src/lib/engine/deepseek.ts"
      via: "reasonWithDeepSeek() in Wave 2 with creator context injected"
      pattern: "reasonWithDeepSeek"
---

<objective>
Create the Creator Context stage and restructure the prediction pipeline to a 10-stage architecture with wave-based parallelism.

Purpose: The current pipeline runs 4 stages linearly. Phase 5 restructures it to 10 stages organized in two parallel waves — Wave 1 runs Gemini + Audio + Creator Context in parallel, Wave 2 runs DeepSeek + Trends in parallel. This enables creator-aware reasoning and reduces total latency through parallelism.

Output: `creator.ts` (new file) and rewritten `pipeline.ts` with wave-based orchestration.
</objective>

<execution_context>
@/Users/davideloreti/.claude/get-shit-done/workflows/execute-plan.md
@/Users/davideloreti/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-types-schema-db-migration/04-01-SUMMARY.md
@.planning/phases/04-types-schema-db-migration/04-02-SUMMARY.md

# Key source files to read before implementing
@src/lib/engine/pipeline.ts
@src/lib/engine/types.ts
@src/lib/engine/normalize.ts
@src/lib/engine/gemini.ts
@src/lib/engine/deepseek.ts
@src/lib/engine/rules.ts
@src/lib/engine/trends.ts
@src/types/database.types.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Creator Context stage</name>
  <files>src/lib/engine/creator.ts</files>
  <action>
Create `src/lib/engine/creator.ts` with:

**CreatorContext interface:**
```typescript
export interface CreatorContext {
  found: boolean;              // Whether creator has a profile
  follower_count: number | null;
  avg_views: number | null;    // Computed or from profile
  engagement_rate: number | null;
  niche: string | null;
  posting_frequency: string | null; // e.g., "daily", "weekly" — derived or null
  platform_averages: {         // Cold start baseline (always present)
    avg_views: number;
    avg_engagement_rate: number;
    avg_share_rate: number;
    avg_comment_rate: number;
  };
}
```

**fetchCreatorContext function:**
- Accepts `supabase` client, `creator_handle: string | null`, and `niche: string | null`
- If `creator_handle` is provided, query `creator_profiles` table by `tiktok_handle` (the schema has `tiktok_handle` column). Look up the creator's profile for follower count, engagement rate, niches.
- **Cold start baseline**: Always compute platform-wide averages from `scraped_videos` table. Run a single aggregate query:
  ```sql
  SELECT
    AVG(views) as avg_views,
    AVG(CASE WHEN views > 0 THEN (likes + comments * 2 + shares * 3)::float / views ELSE 0 END) as avg_engagement_rate,
    AVG(CASE WHEN views > 0 THEN shares::float / views ELSE 0 END) as avg_share_rate,
    AVG(CASE WHEN views > 0 THEN comments::float / views ELSE 0 END) as avg_comment_rate
  FROM scraped_videos
  WHERE views > 0
  ```
  Cache this result in a module-level variable (same pattern as calibration data caching in gemini.ts/deepseek.ts) — platform averages don't change per-request.
- Return `CreatorContext` with `found: true` + profile data if creator found, or `found: false` with just the platform_averages.
- **Important**: Creator data is CONTEXT ONLY — feeds into AI prompts for reasoning but does NOT directly modify the aggregated score. This function just fetches the data; the pipeline passes it to DeepSeek.

**formatCreatorContext helper:**
- Takes `CreatorContext` and returns a string for DeepSeek prompt injection
- When `found: true`: Include follower count, avg views, engagement rate, niche
- When `found: false`: Include platform-wide averages as "typical creator baseline"
- Output like:
  ```
  ## Creator Context
  Creator profile: [found/not found]
  Follower count: X
  Average views: Y
  Engagement rate: Z%
  Platform average engagement: W%
  ```
  This string will be appended to the DeepSeek prompt in the pipeline.
  </action>
  <verify>
Run `npx tsc --noEmit --skipLibCheck` — zero errors in creator.ts. Verify the file exports `CreatorContext`, `fetchCreatorContext`, and `formatCreatorContext`.
  </verify>
  <done>
creator.ts exists with typed CreatorContext interface, fetchCreatorContext that queries creator_profiles with scraped_videos cold-start baseline, and formatCreatorContext for prompt injection.
  </done>
</task>

<task type="auto">
  <name>Task 2: Restructure pipeline to 10-stage wave architecture</name>
  <files>src/lib/engine/pipeline.ts</files>
  <action>
Rewrite `src/lib/engine/pipeline.ts` to implement the 10-stage wave-based pipeline. The current file has a simple 4-stage linear flow — replace it entirely.

**Pipeline stages (10 stages, 2 waves):**

1. **Validate** — Parse input with AnalysisInputSchema
2. **Normalize** — Convert AnalysisInput to ContentPayload via normalizeInput()
3. **Wave 1** (parallel via Promise.all — NOT allSettled, since all stages are required):
   - Stage 3: **Gemini Analysis** — analyzeWithGemini(validated) for text, or analyzeVideoWithGemini() if has video
   - Stage 4: **Audio Analysis** — placeholder for Phase 11 (return null for now, but stage must exist in the pipeline structure)
   - Stage 5: **Creator Context** — fetchCreatorContext(supabase, payload.creator_handle, payload.niche)
   - Stage 6: **Rule Loading** — loadActiveRules(supabase, payload.content_type) + scoreContentAgainstRules(payload.content_text, rules)
4. **Wave 2** (parallel via Promise.all):
   - Stage 7: **DeepSeek Reasoning** — reasonWithDeepSeek() with all Wave 1 outputs as context, including creator context string
   - Stage 8: **Trend Enrichment** — enrichWithTrends(supabase, validated)
5. Stage 9: **Aggregate** — combine all signals (delegated to aggregator, will be rewritten in Plan 02)
6. Stage 10: **Finalize** — attach metadata (timing, cost, engine version)

**Per-stage timing:**
Wrap each stage in a timing helper. Capture `{ stage: string, duration_ms: number }` for each stage. Store in a `StageTiming[]` array passed to the aggregator.

```typescript
interface StageTiming {
  stage: string;
  duration_ms: number;
}
```

Use a helper function:
```typescript
async function timed<T>(name: string, timings: StageTiming[], fn: () => Promise<T>): Promise<T> {
  const start = performance.now();
  const result = await fn();
  timings.push({ stage: name, duration_ms: Math.round(performance.now() - start) });
  return result;
}
```

For parallel stages in Wave 1/Wave 2, time each individual stage AND the overall wave.

**Strict failure mode (per user decision):**
- Use `Promise.all()` (NOT `Promise.allSettled()`) — if any stage throws, the entire pipeline fails immediately.
- Wrap each stage call in a try/catch that re-throws with a specific error message identifying the stage:
  ```typescript
  try {
    result = await analyzeWithGemini(validated);
  } catch (error) {
    throw new Error(`Analysis failed: Gemini content analysis — ${error instanceof Error ? error.message : String(error)}`);
  }
  ```
- The PIPE-04 requirement says Promise.allSettled(), but the user LOCKED DECISION overrides this: "All stages are required — if any stage fails, the entire analysis fails." Honor the user decision.

**DeepSeek context injection:**
- DeepSeek currently receives `{ input, gemini_analysis, rule_result, trend_enrichment }`.
- Extend this: the pipeline should pass creator context to DeepSeek. Since we can't change DeepSeek's interface in this plan (that's aggregator scope), append the creator context string to the DeepSeek input's content. Specifically, the `DeepSeekInput` interface in deepseek.ts already has `input: AnalysisInput` — we need to extend this.
- **Approach**: Add `creator_context?: string` to the DeepSeekInput interface in deepseek.ts (minimal change). In buildDeepSeekPrompt, if creator_context is provided, append it after the trend context section. This is a 2-line addition to deepseek.ts.

**Function signature change:**
```typescript
export async function runPredictionPipeline(
  input: AnalysisInput
): Promise<PipelineResult>
```

Where `PipelineResult` is a new interface holding all stage outputs + timings:
```typescript
export interface PipelineResult {
  // Stage outputs
  payload: ContentPayload;
  geminiResult: { analysis: GeminiAnalysis; cost_cents: number };
  creatorContext: CreatorContext;
  ruleResult: RuleScoreResult;
  trendEnrichment: TrendEnrichment;
  deepseekResult: { reasoning: DeepSeekReasoning; cost_cents: number } | null;
  audioResult: null; // Placeholder for Phase 11

  // Pipeline metadata
  timings: StageTiming[];
  total_duration_ms: number;
}
```

Note: The pipeline now returns raw stage outputs instead of directly calling aggregateScores. The API route (Plan 02) will call aggregateScores with these outputs. This separates orchestration (pipeline) from scoring (aggregator).

**Important notes:**
- Import `normalizeInput` from `./normalize`
- Import `fetchCreatorContext` from `./creator`
- Import `formatCreatorContext` from `./creator` for DeepSeek prompt injection
- The `enrichWithTrends` function currently takes `AnalysisInput` — pass `validated` (the original validated input), not `payload` (the ContentPayload), since the function signature expects AnalysisInput.
- DeepSeek currently can return null when circuit breaker is open. Per user decision, all stages are required. However, the circuit breaker returning null is a RECOVERY mechanism, not a stage failure. For now, if DeepSeek returns null (circuit breaker open), throw: `"Analysis failed: DeepSeek reasoning — service temporarily unavailable (circuit breaker open)"`. This enforces the "all required" decision while keeping the circuit breaker pattern for Phase 6 to refine.
  </action>
  <verify>
Run `npx tsc --noEmit --skipLibCheck` — zero type errors. Verify pipeline.ts exports `runPredictionPipeline`, `PipelineResult`, and `StageTiming`.
  </verify>
  <done>
pipeline.ts restructured with 10 stages in 2 waves, per-stage timing, strict fail-all mode with specific error messages, creator context integrated into Wave 1, and PipelineResult output type.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit --skipLibCheck` passes with zero errors
2. `creator.ts` exports CreatorContext, fetchCreatorContext, formatCreatorContext
3. `pipeline.ts` exports runPredictionPipeline, PipelineResult, StageTiming
4. Pipeline uses Promise.all (not allSettled) for both waves
5. Stage failure produces error message identifying which stage failed
6. Creator Context runs in Wave 1 parallel with Gemini
7. Per-stage timing captured for every stage
</verification>

<success_criteria>
- Pipeline file has Wave 1 (Gemini + Audio + Creator + Rules parallel) and Wave 2 (DeepSeek + Trends parallel) structure
- Creator Context queries creator_profiles with scraped_videos cold-start fallback
- Any stage failure produces specific error (e.g., "Analysis failed: Gemini content analysis — ...")
- StageTiming array captures duration for each stage
- PipelineResult separates orchestration output from scoring
</success_criteria>

<output>
After completion, create `.planning/phases/05-pipeline-architecture/05-01-SUMMARY.md`
</output>
