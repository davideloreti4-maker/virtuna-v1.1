---
phase: 02-ml-model-rehabilitation
plan: 03
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - src/app/api/cron/retrain-ml/route.ts
autonomous: true

must_haves:
  truths:
    - "retrain-ml cron queries scraped_videos from Supabase and generates training features dynamically"
    - "Tier assignment uses percentile-based quintiles (20/40/60/80th percentile of view counts)"
    - "Training data is split with stratifiedSplit() for proportional tier representation in train/test"
    - "Cron skips model replacement when test accuracy is below 60%"
    - "saveRate is estimated using likes * 0.15 proxy (scraped_videos has no saves column)"
    - "Cron falls back to training-data.json when scraped_videos has fewer than 500 rows"
    - "Per-class precision/recall is logged after training via logPerClassMetrics"
  artifacts:
    - path: "src/app/api/cron/retrain-ml/route.ts"
      provides: "Dynamic training data generation from scraped_videos with accuracy gate"
      contains: "scraped_videos"
  key_links:
    - from: "src/app/api/cron/retrain-ml/route.ts"
      to: "supabase.scraped_videos"
      via: "Supabase query for training data"
      pattern: 'from.*scraped_videos'
    - from: "src/app/api/cron/retrain-ml/route.ts"
      to: "src/lib/engine/ml.ts:trainModel"
      via: "Passes structured data object (not file path)"
      pattern: "trainModel.*trainSet"
    - from: "src/app/api/cron/retrain-ml/route.ts"
      to: "src/lib/engine/ml.ts:stratifiedSplit"
      via: "Import and call for train/test partitioning"
      pattern: "stratifiedSplit"
---

<objective>
Rewrite the retrain-ml cron to generate training data dynamically from scraped_videos, assign tiers via percentile-based quintiles, use stratified splitting, and gate model replacement on >60% accuracy.

Purpose: Replace the static 2.6MB training-data.json with live data from the scraping pipeline so the model stays current as new videos are scraped.

Output: A retrain-ml cron that queries Supabase, computes features, assigns tiers, trains with class weighting, and only deploys the model if accuracy exceeds 60%.
</objective>

<execution_context>
@/Users/davideloreti/.claude/get-shit-done/workflows/execute-plan.md
@/Users/davideloreti/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-ml-model-rehabilitation/02-RESEARCH.md
@.planning/phases/02-ml-model-rehabilitation/02-01-SUMMARY.md
@src/app/api/cron/retrain-ml/route.ts
@src/lib/engine/ml.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build videoToFeatures and assignTiers helpers in the cron route</name>
  <files>src/app/api/cron/retrain-ml/route.ts</files>
  <action>
Rewrite the retrain-ml cron route with dynamic training data generation. The entire route.ts file will be substantially rewritten.

**Add maxDuration** at the top:
```typescript
export const maxDuration = 120; // Training with dynamic data may take up to ~60s
```

**Add helper functions** (inside the file, not exported — they're cron-internal):

1. `clamp01(v: number): number` — `Math.max(0, Math.min(1, v))`

2. `videoToFeatures(video: ScrapedVideo): number[]`
   - Compute engagement rates from raw metrics:
     - `views = video.views ?? 1` (avoid div by zero)
     - `likes = video.likes ?? 0`, `shares = video.shares ?? 0`, `comments = video.comments ?? 0`
     - `estimatedSaves = likes * 0.15` (no saves column in scraped_videos — industry proxy)
     - `shareRate = clamp01(shares / views)`
     - `commentRate = clamp01(comments / views)`
     - `likeRate = clamp01(likes / views)`
     - `saveRate = clamp01(estimatedSaves / views)`
     - `shareToLikeRatio = likes > 0 ? clamp01(shares / likes) : 0`
     - `commentToLikeRatio = likes > 0 ? clamp01(comments / likes) : 0`
     - `durationSeconds = clamp01((video.duration_seconds ?? 30) / 180)`
     - `hashtagCount = clamp01((Array.isArray(video.hashtags) ? video.hashtags.length : 0) / 30)`
     - `hasTrendingSound = video.sound_name ? 1 : 0`
     - `captionLength = clamp01((video.description?.length ?? 0) / 2000)`
     - `hasFollowerData = 0`
     - `followerTier = 0.5`
     - `viewsPerFollower = 0`
     - Temporal features from `video.created_at`:
       - `weekdayPosted = new Date(video.created_at ?? Date.now()).getUTCDay() / 6`
       - `hourPosted = new Date(video.created_at ?? Date.now()).getUTCHours() / 23`
   - Return the 15-element array in exact feature order matching training-data.json featureNames.

3. `assignTiers(views: number[]): number[]`
   - Sort a copy of views ascending.
   - Compute p20, p40, p60, p80 percentile boundaries.
   - Map each view count to tier 1-5 based on boundaries.
   - Return array of tier labels (1-indexed).

**Define a minimal type** for the Supabase row (or use the existing database types if imported):
```typescript
interface ScrapedVideo {
  views: number | null;
  likes: number | null;
  shares: number | null;
  comments: number | null;
  duration_seconds: number | null;
  hashtags: string[] | null;
  sound_name: string | null;
  description: string | null;
  created_at: string | null;
}
```
  </action>
  <verify>
    Run `npx tsc --noEmit` — no type errors.
    Verify videoToFeatures returns exactly 15 elements.
    Verify assignTiers returns 1-5 values only.
  </verify>
  <done>
    videoToFeatures and assignTiers helpers are implemented with correct feature order, save estimation proxy, and percentile-based tier assignment.
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire dynamic data query, stratified split, accuracy gate, and fallback into GET handler</name>
  <files>src/app/api/cron/retrain-ml/route.ts</files>
  <action>
Rewrite the GET handler body:

1. **Import stratifiedSplit and trainModel** from ml.ts:
   ```typescript
   import { trainModel, stratifiedSplit } from "@/lib/engine/ml";
   ```

2. **Query scraped_videos** from Supabase:
   ```typescript
   const { data: videos, error: queryError } = await supabase
     .from("scraped_videos")
     .select("views, likes, shares, comments, duration_seconds, hashtags, sound_name, description, created_at")
     .not("views", "is", null)
     .not("likes", "is", null)
     .gt("views", 0)
     .order("created_at", { ascending: false })
     .limit(10000);
   ```

3. **Fallback logic**: If `videos` is null, has queryError, or has fewer than 500 rows, fall back to the old file-based training:
   ```typescript
   if (!videos || videos.length < 500) {
     console.log(`[retrain-ml] Only ${videos?.length ?? 0} scraped videos — falling back to training-data.json`);
     const result = await trainModel(); // Uses default file path
     // ... return response
   }
   ```

4. **Generate features + labels**:
   ```typescript
   const features = videos.map(v => videoToFeatures(v));
   const viewCounts = videos.map(v => v.views ?? 0);
   const labels = assignTiers(viewCounts);
   ```

5. **Log tier distribution** for diagnostics:
   ```typescript
   const tierCounts = [0, 0, 0, 0, 0];
   for (const label of labels) tierCounts[label - 1]++;
   console.log(`[retrain-ml] Tier distribution: ${tierCounts.map((c, i) => `T${i+1}=${c}`).join(' ')}`);
   ```

6. **Stratified split** (import `seededRandom` from ml.ts — or since it's not exported, use a local simple seeded RNG, or export it):

   Actually, `stratifiedSplit` from Plan 02-01 takes an `rng` parameter. Use a simple inline seeded RNG in the cron:
   ```typescript
   // Simple seeded RNG for reproducible splits
   let seed = 42;
   const rng = () => {
     seed = (seed * 1664525 + 1013904223) & 0xffffffff;
     return (seed >>> 0) / 0xffffffff;
   };
   const split = stratifiedSplit(features, labels, 0.2, rng);
   ```

7. **Feature names** (must match training-data.json order):
   ```typescript
   const featureNames = [
     "shareRate", "commentRate", "likeRate", "saveRate",
     "shareToLikeRatio", "commentToLikeRatio",
     "durationSeconds", "hashtagCount", "hasTrendingSound", "captionLength",
     "hasFollowerData", "followerTier", "viewsPerFollower",
     "weekdayPosted", "hourPosted"
   ];
   ```

8. **Call trainModel with structured data**:
   ```typescript
   const result = await trainModel({
     trainSet: split.train,
     testSet: split.test,
     featureNames,
   });
   ```

9. **Accuracy gate**: If `result.testAccuracy < 0.60`, log a warning and DO NOT let the model persist (trainModel already persists — so we need to handle this). Two approaches:
   - **Option A (recommended)**: Pass an `accuracyGate` option to trainModel that prevents upload. But Plan 02-01 doesn't add this.
   - **Option B**: After trainModel returns, if accuracy < 0.60, restore the previous weights from storage. This is complex.
   - **Option C (simplest)**: Check accuracy BEFORE trainModel persists. But trainModel always persists.

   **Best approach**: Modify the cron to split training into two steps — train locally (compute weights) then conditionally persist. Since trainModel() always persists, we need a different approach.

   Actually, the simplest approach: let trainModel run (it will persist regardless), then if accuracy < 0.60, log a warning and the RESPONSE indicates the model was not good enough. The old weights were already overwritten though.

   **Correct approach**: Since trainModel always uploads, add a `skipPersist` boolean option to trainModel or handle it in the cron by deleting the bad weights after. BUT Plan 02-01 already changes trainModel — we can coordinate.

   Instead, in this plan's task: after calling trainModel, if `result.testAccuracy < 0.60`, delete the uploaded weights from Supabase Storage so the old cached/fallback weights remain. This is clean and doesn't require changing trainModel further:
   ```typescript
   if (result.testAccuracy < 0.60) {
     console.warn(`[retrain-ml] Test accuracy ${(result.testAccuracy * 100).toFixed(1)}% below 60% gate — removing uploaded weights`);
     await supabase.storage.from("ml-weights").remove(["model/ml-weights.json"]);
     return NextResponse.json({
       status: "skipped",
       reason: `Test accuracy ${(result.testAccuracy * 100).toFixed(1)}% below 60% gate`,
       testAccuracy: Math.round(result.testAccuracy * 1000) / 1000,
       trainAccuracy: Math.round(result.trainAccuracy * 1000) / 1000,
       confusionMatrix: result.confusionMatrix,
       videoCount: videos.length,
       tierDistribution: tierCounts,
     });
   }
   ```

10. **Success response**:
   ```typescript
   return NextResponse.json({
     status: "completed",
     trainAccuracy: Math.round(result.trainAccuracy * 1000) / 1000,
     testAccuracy: Math.round(result.testAccuracy * 1000) / 1000,
     confusionMatrix: result.confusionMatrix,
     videoCount: videos.length,
     tierDistribution: tierCounts,
     trainedAt: new Date().toISOString(),
   });
   ```

Keep the existing verifyCronAuth check at the top. Remove the old outcome count query (it was informational only and is no longer relevant to the dynamic flow).
  </action>
  <verify>
    Run `npx tsc --noEmit` — no type errors.
    Grep route.ts for `scraped_videos` — should appear in the Supabase query.
    Grep for `stratifiedSplit` — should appear as import and call.
    Grep for `0.60` or `60%` — accuracy gate check should be present.
    Grep for `training-data.json` — should appear only in the fallback path.
  </verify>
  <done>
    retrain-ml cron queries up to 10K scraped_videos, generates features with save proxy, assigns tiers via percentiles, uses stratified split, calls trainModel with structured data, gates on 60% accuracy (removes bad weights), and falls back to training-data.json when insufficient scraped data.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with zero errors
2. Cron queries scraped_videos with correct column selection and filters
3. Tier assignment produces 1-5 labels using percentile quintiles
4. stratifiedSplit is called for proportional train/test partitioning
5. trainModel receives structured data object (not file path) for dynamic data
6. Accuracy < 60% triggers weight removal from Supabase Storage and "skipped" response
7. Fallback to training-data.json when < 500 scraped videos
8. Tier distribution is logged for monitoring
9. maxDuration = 120 is set for the route
</verification>

<success_criteria>
- retrain-ml cron produces fresh training data from scraped_videos on every run
- Tiers assigned via percentile boundaries (no hardcoded view count thresholds)
- Model only persists when accuracy > 60%
- Falls back gracefully when insufficient scraped data
- Per-class metrics logged for every training run
</success_criteria>

<output>
After completion, create `.planning/phases/02-ml-model-rehabilitation/02-03-SUMMARY.md`
</output>
