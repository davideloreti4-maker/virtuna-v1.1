---
phase: 02-gemini-prompt-video-analysis
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/engine/types.ts
  - src/lib/engine/gemini.ts
autonomous: true

must_haves:
  truths:
    - "Gemini returns exactly 5 TikTok-aligned factors (Scroll-Stop Power, Completion Pull, Rewatch Potential, Share Trigger, Emotional Charge) each scored 0.0-10.0"
    - "Each factor includes a score, rationale, and actionable improvement tip"
    - "Text/script-only analysis works without video input"
    - "When video is provided, Gemini analyzes visual content and returns video-specific signals (visual_production_quality, hook_visual_impact, pacing_score, transition_quality)"
    - "Video analysis fails hard on error — no partial/fallback results"
    - "Calibration thresholds from calibration-baseline.json are embedded in the prompt at runtime"
    - "Cost estimation uses actual token-based pricing instead of hardcoded values"
  artifacts:
    - path: "src/lib/engine/types.ts"
      provides: "GeminiResponseSchema v2 with 5 TikTok factors + video signals"
      contains: "scroll_stop_power|completion_pull|rewatch_potential|share_trigger|emotional_charge"
    - path: "src/lib/engine/gemini.ts"
      provides: "analyzeWithGemini v2 with text + video code paths, calibration embedding"
      exports: ["analyzeWithGemini", "GEMINI_MODEL"]
  key_links:
    - from: "src/lib/engine/gemini.ts"
      to: "src/lib/engine/calibration-baseline.json"
      via: "fs.readFile at runtime"
      pattern: "calibration-baseline\\.json"
    - from: "src/lib/engine/gemini.ts"
      to: "src/lib/engine/types.ts"
      via: "GeminiResponseSchema import for Zod validation"
      pattern: "GeminiResponseSchema"
---

<objective>
Rewrite Gemini prompt and response schema to return 5 TikTok-aligned factors (Scroll-Stop Power, Completion Pull, Rewatch Potential, Share Trigger, Emotional Charge) with calibration data embedded from Phase 1 analysis. Add full video analysis via Gemini Flash file upload. Text-only analysis continues to work as a separate code path.

Purpose: Transform Gemini from generic content analysis (Hook Strength, Emotional Resonance, Clarity, Originality, Call to Action) to TikTok-specific factor evaluation grounded in real data. Enable video content analysis for the first time.
Output: Updated types.ts (GeminiResponseSchema v2) and gemini.ts (rewritten prompt, text+video paths, calibration embedding, token-based costs)
</objective>

<execution_context>
@/Users/davideloreti/.claude/get-shit-done/workflows/execute-plan.md
@/Users/davideloreti/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/lib/engine/types.ts
@src/lib/engine/gemini.ts
@src/lib/engine/calibration-baseline.json
@src/lib/engine/pipeline.ts
@src/lib/engine/aggregator.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Rewrite GeminiResponseSchema + prompt template + text-mode analysis</name>
  <files>src/lib/engine/types.ts, src/lib/engine/gemini.ts</files>
  <action>
**types.ts changes:**

1. Replace `GeminiResponseSchema` with v2 schema. The new schema has:
   - `factors`: array of exactly 5 objects, each with:
     - `name`: string (one of "Scroll-Stop Power", "Completion Pull", "Rewatch Potential", "Share Trigger", "Emotional Charge")
     - `score`: number 0-10 (one decimal precision, e.g. 7.3)
     - `rationale`: string (1-2 sentences explaining why this score)
     - `improvement_tip`: string (actionable niche-aware suggestion)
   - `overall_impression`: string (summary of content's viral potential)
   - `content_summary`: string (brief summary of content)
   - `video_signals`: optional object (only present for video inputs), with:
     - `visual_production_quality`: number 0-10
     - `hook_visual_impact`: number 0-10
     - `pacing_score`: number 0-10
     - `transition_quality`: number 0-10

2. Remove the old flat fields (hook_strength, emotional_resonance, clarity, originality, call_to_action) from GeminiResponseSchema.

3. Update `FactorSchema` to match new factor shape (replace `description` + `tips: string[]` with `rationale: string` + `improvement_tip: string`).

4. Update the `GeminiAnalysis` type alias accordingly.

5. Keep `AnalysisInputSchema` unchanged for now (Phase 4 expands it).

**gemini.ts changes:**

1. Switch `GEMINI_MODEL` default from `"gemini-2.5-flash-lite"` to `"gemini-2.5-flash"` (per user decision: Gemini Flash for both text and video).

2. Create `loadCalibrationData()` function that reads `calibration-baseline.json` at runtime using `fs.readFile` (Node.js fs/promises). Cache the result in a module-level variable so it's only read once per cold start. Returns the parsed JSON. This is a server-side file, safe to use Node fs.

3. Rewrite `ANALYSIS_PROMPT` as a function `buildTextPrompt(input: AnalysisInput, calibration: CalibrationData, niche?: string)` that returns the prompt string. The prompt must:
   - Define the 5 factors with clear descriptions:
     - **Scroll-Stop Power**: Would a user stop scrolling? Measures hook strength, curiosity gap, pattern interrupt, opening frame/line impact.
     - **Completion Pull**: Would a user watch to the end? Measures narrative tension, pacing, payoff anticipation, information drip.
     - **Rewatch Potential**: Would a user watch again? Measures layered meaning, satisfying loops, "wait what" moments, rewatchable reveals.
     - **Share Trigger**: Would a user share this? Measures relatability, identity signaling, emotional provocation, "tag someone" energy.
     - **Emotional Charge**: Does this make the user FEEL something? Measures intensity of emotion (joy, outrage, awe, nostalgia, humor), not which emotion.
   - Instruct absolute scoring: 0.0-10.0, one decimal, universal quality standards. NOT niche-relative. Most content should score 4-7; scores above 8 are exceptional.
   - Each factor needs: score + rationale (1-2 sentences WHY) + improvement_tip (actionable, niche-aware if niche provided)
   - Embed key calibration thresholds from the loaded JSON:
     - Viral share rate threshold (p90): {calibration.primary_kpis.share_rate.viral_threshold}
     - Viral weighted engagement score (p90): {calibration.primary_kpis.weighted_engagement_score.percentiles.p90}
     - Duration sweet spot: {calibration.duration_analysis.sweet_spot_by_weighted_score.optimal_range_seconds}
     - Viral vs average differentiators (top 3 by difference_pct)
   - Include the niche in the user message section (not the system prompt) if provided
   - Instruct: "Score content quality only. Do NOT apply algorithm weights or predict engagement metrics — that happens downstream."
   - Return JSON matching the schema exactly

4. Rewrite the `RESPONSE_SCHEMA` (Gemini structured output schema) to match the new v2 GeminiResponseSchema. Use the `Type` enum from `@google/genai`. The schema must:
   - `factors` array with `name`, `score`, `rationale`, `improvement_tip`
   - `overall_impression` and `content_summary`
   - Do NOT include `video_signals` in the structured schema for text mode (video mode builds its own schema — see Task 2)

5. Update `analyzeWithGemini` function:
   - Keep the same signature: `(input: AnalysisInput) => Promise<{ analysis: GeminiAnalysis; cost_cents: number }>`
   - Call `loadCalibrationData()` to get thresholds
   - Use `buildTextPrompt()` to construct the prompt
   - Extract niche from `input.society_id` field if present (pass as niche parameter)
   - Replace hardcoded `cost_cents = 0.001 * (attempt + 1)` with token-based estimation:
     - Read `response.usageMetadata?.promptTokenCount` and `candidatesTokenCount` from the Gemini response
     - Flash pricing: input $0.15/1M tokens, output $0.60/1M tokens (as of 2025 pricing)
     - Calculate: `(promptTokens * 0.15 + outputTokens * 0.60) / 1_000_000 * 100` (cents)
     - If usageMetadata not available, fallback to estimate: ~2000 input tokens, ~800 output tokens
   - Add soft cost cap: if cost_cents > 0.5 (per analysis), log a warning via `console.warn` but do NOT abort

6. Update `parseGeminiResponse` to use the new `GeminiResponseSchema`.

7. Update `analyzeImageWithGemini` to be a thin wrapper or remove it — it will be replaced by the video analysis path in Task 2. For now, keep it but mark with a `@deprecated` JSDoc tag.
  </action>
  <verify>
Run `npx tsc --noEmit` to confirm types compile. Grep for the 5 factor names in gemini.ts to confirm prompt includes them. Verify calibration-baseline.json is imported. Verify the old factor names (Hook Strength, Emotional Resonance, Clarity, Originality, Call to Action) no longer appear in the prompt or schema.
  </verify>
  <done>
GeminiResponseSchema v2 validates the 5 TikTok factors with score/rationale/improvement_tip. Text-mode analyzeWithGemini uses the new prompt with embedded calibration data. Cost estimation uses token-based pricing. Old v1 factor names removed from schema and prompt.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add video analysis code path with file upload</name>
  <files>src/lib/engine/gemini.ts, src/lib/engine/types.ts</files>
  <action>
**gemini.ts — video analysis:**

1. Create `analyzeVideoWithGemini(videoBuffer: Buffer, mimeType: string, niche?: string)` function:
   - Accepts a `Buffer` of video data and its MIME type (e.g., `"video/mp4"`)
   - Validates duration cap: check video buffer size as proxy — if > 50MB, reject with error "Video exceeds maximum size (50MB / ~3 minutes)". Exact duration validation happens upstream in Phase 7; this is a safety net.
   - Uploads video to Gemini Files API: `const file = await ai.files.upload(new Blob([videoBuffer], { type: mimeType }), { mimeType })`
   - Poll for file processing completion: loop checking `ai.files.get({ name: file.name })` until `file.state === "ACTIVE"`, with 500ms intervals and 60s timeout. Throw if state is `"FAILED"`.
   - Build video-specific prompt via `buildVideoPrompt(calibration, niche?)`:
     - Same 5 factors as text mode but instructed to evaluate visual/audio content
     - Additional section requesting video_signals: visual_production_quality (lighting, framing, resolution), hook_visual_impact (first 3 seconds visual hook), pacing_score (cut frequency, rhythm, dead air), transition_quality (smooth cuts, creative transitions, visual flow)
     - Each video_signal: scored 0-10 with same one-decimal precision
   - Build video response schema (`VIDEO_RESPONSE_SCHEMA`): same as text schema plus `video_signals` object with the 4 fields
   - Call `ai.models.generateContent` with:
     - `model: GEMINI_MODEL`
     - `contents: [{ role: "user", parts: [{ text: videoPrompt }, { fileData: { fileUri: file.uri, mimeType } }] }]`
     - `config: { responseMimeType: "application/json", responseSchema: VIDEO_RESPONSE_SCHEMA }`
   - Parse response with a video-specific Zod schema that includes video_signals (create `GeminiVideoResponseSchema` in types.ts that extends the base schema with required video_signals)
   - Calculate cost: use usageMetadata tokens with Flash pricing. Video tokens are counted automatically by Gemini.
   - Soft cost cap: warn if cost_cents > 2.0 for video (higher threshold than text)
   - On ANY error during video analysis: throw immediately with descriptive message. No partial results, no fallback to text mode. The error message should indicate whether it was upload failure, processing timeout, or analysis failure.
   - Clean up: after analysis, delete the uploaded file via `ai.files.delete({ name: file.name })` in a finally block (best-effort, don't throw if delete fails)

2. Return type for video: `{ analysis: GeminiVideoAnalysis; cost_cents: number }` where `GeminiVideoAnalysis` is the video-extended schema type.

**types.ts — video schema:**

1. Create `GeminiVideoSignalsSchema` as a Zod object:
   - `visual_production_quality`: z.number().min(0).max(10)
   - `hook_visual_impact`: z.number().min(0).max(10)
   - `pacing_score`: z.number().min(0).max(10)
   - `transition_quality`: z.number().min(0).max(10)

2. Create `GeminiVideoResponseSchema` that extends `GeminiResponseSchema` with `.extend({ video_signals: GeminiVideoSignalsSchema })`.

3. Export `GeminiVideoAnalysis` type: `z.infer<typeof GeminiVideoResponseSchema>`.

4. Export `GeminiVideoSignals` type: `z.infer<typeof GeminiVideoSignalsSchema>`.

**Important implementation notes:**
- The `@google/genai` SDK's `files.upload()` accepts `string | Blob`. On Node.js (server-side), convert `Buffer` to `Blob` via `new Blob([buffer], { type: mimeType })`.
- File states from Gemini: `"PROCESSING"`, `"ACTIVE"`, `"FAILED"`. Must wait for `"ACTIVE"` before using in generateContent.
- TIMEOUT_MS for video should be higher than text (30s vs 15s) since video analysis takes longer.
- Keep existing `analyzeWithGemini` for text, add `analyzeVideoWithGemini` as a separate export. Don't merge them — they have different input shapes and the pipeline (Phase 5) will call the right one based on input mode.
  </action>
  <verify>
Run `npx tsc --noEmit` to confirm types compile. Verify `analyzeVideoWithGemini` is exported from gemini.ts. Verify `GeminiVideoResponseSchema` is exported from types.ts. Grep for `files.upload` and `files.delete` in gemini.ts to confirm upload/cleanup flow. Grep for the 4 video signal names in types.ts.
  </verify>
  <done>
`analyzeVideoWithGemini` accepts a video Buffer, uploads to Gemini Files API, waits for processing, analyzes with video-specific prompt, returns 5 factors + 4 video signals. Errors throw immediately with no fallback. Uploaded files are cleaned up. Video response schema validates all required fields.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with zero errors
2. GeminiResponseSchema v2 has exactly 5 factor names: Scroll-Stop Power, Completion Pull, Rewatch Potential, Share Trigger, Emotional Charge
3. Each factor has: score (0-10), rationale (string), improvement_tip (string)
4. Old factor names (Hook Strength, Emotional Resonance, Clarity, Originality, Call to Action) do NOT appear in types.ts or gemini.ts
5. calibration-baseline.json is loaded dynamically at runtime (not imported as static module)
6. `analyzeWithGemini` (text) and `analyzeVideoWithGemini` (video) are both exported
7. Video function includes file upload, polling, cleanup, and error handling (no partial results)
8. Cost estimation reads usageMetadata token counts, NOT hardcoded values
9. GEMINI_MODEL defaults to "gemini-2.5-flash" (not "gemini-2.5-flash-lite")
10. Downstream consumers (pipeline.ts, aggregator.ts) may have type errors — that's expected and will be fixed in Phase 4/5. Only types.ts and gemini.ts should be modified in this plan.
</verification>

<success_criteria>
- GeminiResponseSchema v2 compiles and validates the 5 TikTok-aligned factors
- Text analysis path works end-to-end with new prompt and calibration data
- Video analysis path compiles with file upload/poll/analyze/cleanup flow
- Token-based cost estimation replaces hardcoded values
- No regression in text-only analysis capability
</success_criteria>

<output>
After completion, create `.planning/phases/02-gemini-prompt-video-analysis/02-01-SUMMARY.md`
</output>
